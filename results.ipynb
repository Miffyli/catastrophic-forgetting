{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catastrophic Forgetting Results Notebook<a name='top'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the data analysis tools and products for all the experiments associated with this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "<a href=#setup>Setup</a>\n",
    "\n",
    "<a href=#experiment_1>Experiment 1</a>\n",
    "> <a href=#experiment_1_validation>Validation Phase</a><br><br>\n",
    "> <a href=#experiment_1_testing>Testing Phase</a><br><br>\n",
    ">> <a href=#experiment_1_testing_hypothesis>Statistical Hypothesis Testing</a><br><br>\n",
    ">> <a href=#experiment_1_testing_plotting>Plotting</a>\n",
    "\n",
    "<a href=#experiment_2_mnist>Experiment 2 MNIST</a>\n",
    "> <a href=#experiment_2_mnist_validation>Validation Phase</a><br><br>\n",
    "> <a href=#experiment_2_mnist_testing>Testing Phase</a>\n",
    "\n",
    "<a href=#experiment_2_mountain_car>Experiment 2 Mountain Car</a>\n",
    "> <a href=#experiment_2_mountain_car_validation>Validation Phase</a><br><br>\n",
    "> <a href=#experiment_2_mountain_car_testing>Testing Phase</a>\n",
    "\n",
    "<a href=#experiment_2_acrobot>Experiment 2 Acrobot</a>\n",
    "> <a href=#experiment_2_acrobot_validation>Validation Phase</a><br><br>\n",
    "> <a href=#experiment_2_acrobot_testing>Testing Phase</a>\n",
    "\n",
    "<a href=#presentation_exclusive>Presentation Exclusive</a>\n",
    "> <a href=#presentation_exclusive_experiment_1>Experiment 1</a><br><br>\n",
    "> <a href=#presentation_exclusive_experiment_2_mountain_car_and_acrobot>Experiment 2 Mountain Car and Acrobot</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup <a name='setup'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import acrobot.tools as ac_tools\n",
    "import collections\n",
    "import copy\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import mnist.tools as mnist_tools\n",
    "import mountain_car.tools as mc_tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import rc\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.patches import Rectangle\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "\n",
    "# setup matplotlib\n",
    "%matplotlib inline\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "rc('text', usetex=True)\n",
    "sns.set_style('ticks')\n",
    "sns.set_context('paper')\n",
    "sns.set_style('ticks')\n",
    "sns.set_context('paper')\n",
    "\n",
    "# setup dict for specifying nice names for legends\n",
    "optimizer_nice_names = {\n",
    "    'constant': 'Constant',\n",
    "    'adam': 'Adam',\n",
    "    'momentum': 'Momentum',\n",
    "    'rms': 'RMSProp',\n",
    "    'sgd': 'SGD'}\n",
    "\n",
    "# setup constant values for plots\n",
    "X_LABEL_PAD = 5\n",
    "Y_LABEL_PAD = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=#top>Back to Top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1<a name='experiment_1'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Phase<a name='experiment_1_validation'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = mnist_tools.load_data(['experiment_1_mnist_validation.json'])\n",
    "rdf = rdf[rdf['success']]\n",
    "E12 = ((1, 2), (3, 4))\n",
    "E34 = ((3, 4), (1, 2))\n",
    "E1234 = ((1, 2, 3, 4), (1, 2), (3, 4))\n",
    "\n",
    "E12_best = mnist_tools.get_best(\n",
    "    mnist_tools.get_summary(rdf[rdf['phases'] == E12]),\n",
    "    mnist_tools.phase_time_metric(2, 50, 2500))\n",
    "E34_best = mnist_tools.get_best(\n",
    "    mnist_tools.get_summary(rdf[rdf['phases'] == E34]),\n",
    "    mnist_tools.phase_time_metric(2, 50, 2500))\n",
    "E1234_best = mnist_tools.get_best(\n",
    "    mnist_tools.get_summary(rdf[rdf['phases'] == E1234]),\n",
    "    mnist_tools.phase_time_metric(1, 50, 2500))\n",
    "print('{}: lr={}, count={}'.format(\n",
    "    'E12',\n",
    "    E12_best['lr'],\n",
    "    int(E12_best['count'][0])))\n",
    "print('{}: lr={}, count={}'.format(\n",
    "    'E34',\n",
    "    E34_best['lr'],\n",
    "    int(E34_best['count'][0])))\n",
    "print('{}: lr={}, count={}'.format(\n",
    "    'E1234',\n",
    "    E1234_best['lr'],\n",
    "    int(E1234_best['count'][0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=#top>Back to Top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Phase<a name='experiment_1_testing'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = mnist_tools.load_data(['experiment_1_mnist_test.json'])\n",
    "rdf = rdf[rdf['success']]\n",
    "E12 = ((1, 2), (3, 4), (1, 2), (3, 4))\n",
    "E34 = ((3, 4), (1, 2), (3, 4), (1, 2))\n",
    "E1234 = ((1, 2, 3, 4), (1, 2), (3, 4))\n",
    "ER = ((1, 2), (3, 4), (1, 2), (3, 4), (1, 2), (3, 4), (1, 2), (3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=#top>Back to Top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical Hypothesis Testing<a name='experiment_1_testing_hypothesis'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "\n",
    "# H1\n",
    "accuracies = list()\n",
    "for k,v in rdf[rdf['phases'] == E12].iterrows():\n",
    "    accuracies.append(v['accuracies'][v['phase_length'][0] - 1][0])\n",
    "h1_t, h1_p = st.ttest_1samp(accuracies, 0.9)\n",
    "h1_p = h1_p / 2\n",
    "text += 'H1: {} with p {}\\n'.format(\n",
    "    'Reject' if (h1_p < 0.01 / 11) and (h1_t >= 0) else 'Fail to Reject',\n",
    "    '= {0:.4f}'.format(h1_p) if abs(h1_p) >= 1e-4 else '< 0.0001')\n",
    "\n",
    "# H2\n",
    "accuracies = list()\n",
    "for k,v in rdf[rdf['phases'] == E12].iterrows():\n",
    "    accuracies.append(v['accuracies'][v['phase_length'][0] + v['phase_length'][1] - 1][1])\n",
    "h2_t, h2_p = st.ttest_1samp(accuracies, 0.9)\n",
    "h2_p = h2_p / 2\n",
    "text += 'H2: {} with p {}\\n'.format(\n",
    "    'Reject' if (h2_p < 0.01 / 11) and (h2_t >= 0) else 'Fail to Reject',\n",
    "    '= {0:.4f}'.format(h2_p) if abs(h2_p) >= 1e-4 else '< 0.0001')\n",
    "\n",
    "# H3\n",
    "accuracies = list()\n",
    "for k,v in rdf[rdf['phases'] == E1234].iterrows():\n",
    "    accuracies.append(v['accuracies'][v['phase_length'][0] - 1][1])\n",
    "h3_t, h3_p = st.ttest_1samp(accuracies, 0.9)\n",
    "h3_p = h3_p / 2\n",
    "text += 'H3: {} with p {}\\n'.format(\n",
    "    'Reject' if (h3_p < 0.01 / 11) and (h3_t >= 0) else 'Fail to Reject',\n",
    "    '= {0:.4f}'.format(h3_p) if abs(h3_p) >= 1e-4 else '< 0.0001')\n",
    "\n",
    "# H4\n",
    "accuracies = list()\n",
    "for k,v in rdf[rdf['phases'] == E1234].iterrows():\n",
    "    accuracies.append(v['accuracies'][v['phase_length'][0] - 1][2])\n",
    "h4_t, h4_p = st.ttest_1samp(accuracies, 0.9)\n",
    "h4_p = h4_p / 2\n",
    "text += 'H4: {} with p {}\\n'.format(\n",
    "    'Reject' if (h4_p < 0.01 / 11) and (h4_t >= 0) else 'Fail to Reject',\n",
    "    '= {0:.4f}'.format(h4_p) if abs(h4_p) >= 1e-4 else '< 0.0001')\n",
    "\n",
    "# H5\n",
    "accuracies = list()\n",
    "for k,v in rdf[rdf['phases'] == E12].iterrows():\n",
    "    accuracies.append(v['accuracies'][v['phase_length'][0] + v['phase_length'][1] - 1][0])\n",
    "h5_t, h5_p = st.ttest_1samp(accuracies, 0.9)\n",
    "h5_p = h5_p / 2\n",
    "text += 'H5: {} with p {}\\n'.format(\n",
    "    'Reject' if (h5_p < 0.01 / 11) and (h5_t < 0) else 'Fail to Reject',\n",
    "    '= {0:.4f}'.format(h5_p) if abs(h5_p) >= 1e-4 else '< 0.0001')\n",
    "\n",
    "# H6\n",
    "accuracies = list()\n",
    "for k,v in rdf[rdf['phases'] == E34].iterrows():\n",
    "    accuracies.append(v['accuracies'][v['phase_length'][0] - 1][0])\n",
    "h6_t, h6_p = st.ttest_1samp(accuracies, 0.9)\n",
    "h6_p = h6_p / 2\n",
    "text += 'H6: {} with p {}\\n'.format(\n",
    "    'Reject' if (h6_p < 0.01 / 11) and (h6_t >= 0) else 'Fail to Reject',\n",
    "    '= {0:.4f}'.format(h6_p) if abs(h6_p) >= 1e-4 else '< 0.0001')\n",
    "\n",
    "# H7\n",
    "accuracies = list()\n",
    "for k,v in rdf[rdf['phases'] == E34].iterrows():\n",
    "    accuracies.append(v['accuracies'][v['phase_length'][0] + v['phase_length'][1] - 1][1])\n",
    "h7_t, h7_p = st.ttest_1samp(accuracies, 0.9)\n",
    "h7_p = h7_p / 2\n",
    "text += 'H7: {} with p {}\\n'.format(\n",
    "    'Reject' if (h7_p < 0.01 / 11) and (h7_t >= 0) else 'Fail to Reject',\n",
    "    '= {0:.4f}'.format(h7_p) if abs(h7_p) >= 1e-4 else '< 0.0001')\n",
    "\n",
    "# H8\n",
    "accuracies = list()\n",
    "for k,v in rdf[rdf['phases'] == E34].iterrows():\n",
    "    accuracies.append(v['accuracies'][v['phase_length'][0] + v['phase_length'][1] - 1][0])\n",
    "h8_t, h8_p = st.ttest_1samp(accuracies, 0.9)\n",
    "h8_p = h8_p / 2\n",
    "text += 'H8: {} with p {}\\n'.format(\n",
    "    'Reject' if (h8_p < 0.01 / 11) and (h8_t < 0) else 'Fail to Reject',\n",
    "    '= {0:.4f}'.format(h8_p) if abs(h8_p) >= 1e-4 else '< 0.0001')\n",
    "\n",
    "# H9\n",
    "P1_time = list()\n",
    "for k,v in rdf[rdf['phases'] == E12].iterrows():\n",
    "    P1_time.append(v['phase_length'][0])\n",
    "P3_time = list()\n",
    "for k,v in rdf[rdf['phases'] == E12].iterrows():\n",
    "    P3_time.append(v['phase_length'][2])\n",
    "h9_t, h9_p = st.ttest_ind(P1_time, P3_time)\n",
    "h9_p = h9_p / 2\n",
    "text += 'H9: {} with p {}\\n'.format(\n",
    "    'Reject' if (h9_p < 0.01 / 11) and (h9_t > 0) else 'Fail to Reject',\n",
    "    '= {0:.4f}'.format(h9_p) if abs(h9_p) >= 1e-4 else '< 0.0001')\n",
    "\n",
    "# H10\n",
    "P2_time = list()\n",
    "for k,v in rdf[rdf['phases'] == E12].iterrows():\n",
    "    P2_time.append(v['phase_length'][1])\n",
    "P4_time = list()\n",
    "for k,v in rdf[rdf['phases'] == E12].iterrows():\n",
    "    P4_time.append(v['phase_length'][3])\n",
    "h10_t, h10_p = st.ttest_ind(P2_time, P4_time)\n",
    "h10_p = h10_p / 2\n",
    "text += 'H10: {} with p {}\\n'.format(\n",
    "    'Reject' if (h10_p < 0.01 / 11) and (h10_t > 0) else 'Fail to Reject',\n",
    "    '= {0:.4f}'.format(h10_p) if abs(h10_p) >= 1e-4 else '< 0.0001')\n",
    "\n",
    "# H11\n",
    "E1234_time = list()\n",
    "for k,v in rdf[rdf['phases'] == E1234].iterrows():\n",
    "    E1234_time.append(v['phase_length'][0])\n",
    "E12_time = list()\n",
    "for k,v in rdf[rdf['phases'] == E12].iterrows():\n",
    "    E12_time.append(v['phase_length'][0] + v['phase_length'][1])\n",
    "h11_t, h11_p = st.ttest_ind(E1234_time, E12_time)\n",
    "text += 'H11: {} with p {}\\n'.format(\n",
    "    'Reject' if (h11_p < 0.01 / 11) else 'Fail to Reject',\n",
    "    '= {0:.4f}'.format(h11_p) if abs(h11_p) >= 1e-4 else '< 0.0001')\n",
    "\n",
    "with open('experiment_1_hypotheses.txt', 'w') as outfile:\n",
    "    print(text, file=outfile)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=#top>Back to Top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting<a name='experiment_1_testing_plotting'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_phase_lengths = list()\n",
    "for _, row in rdf.iterrows():\n",
    "    for i, l in enumerate(row['phase_length']):\n",
    "        if len(max_phase_lengths) == i:\n",
    "            max_phase_lengths.append(0)\n",
    "        max_phase_lengths[i] = max(max_phase_lengths[i], l)\n",
    "data = dict()\n",
    "for k in rdf['phases'].unique():\n",
    "    data[k] = dict()\n",
    "    for k2 in ['d1_count',\n",
    "               'd2_count']:\n",
    "        data[k][k2] = [np.zeros(i, dtype=int) for i in max_phase_lengths]\n",
    "    for k2 in ['d1_avg',\n",
    "               'd1_sec',\n",
    "               'd1_min',\n",
    "               'd1_max',\n",
    "               'd2_avg',\n",
    "               'd2_sec',\n",
    "               'd2_min',\n",
    "               'd2_max']:\n",
    "        data[k][k2] = [np.zeros(i, dtype=float) for i in max_phase_lengths]\n",
    "    data[k]['phase_lengths'] = [list() for i in max_phase_lengths]\n",
    "    for i in range(len(max_phase_lengths)):\n",
    "        data[k]['d1_min'][i] += 1\n",
    "        data[k]['d2_min'][i] += 1\n",
    "\n",
    "    kdf = rdf[rdf['phases'] == k]\n",
    "    for _, row in kdf.iterrows():\n",
    "        j = 0\n",
    "        for i, l in enumerate(row['phase_length']):\n",
    "            data[k]['phase_lengths'][i].append(l)\n",
    "\n",
    "            if k == E1234:\n",
    "                d1_index = 1\n",
    "                d2_index = 2\n",
    "            elif k == E12:\n",
    "                d1_index = 0\n",
    "                d2_index = 1\n",
    "            elif k == E34:\n",
    "                d1_index = 1\n",
    "                d2_index = 0\n",
    "            else:\n",
    "                assert k == ER\n",
    "                d1_index = 0\n",
    "                d2_index = 1\n",
    "\n",
    "            values = np.array(row['accuracies'])[j:j + l, d1_index]\n",
    "            mask = np.where(np.array(np.invert(np.isnan(values)), dtype=int))[0]\n",
    "            values = values[mask]\n",
    "            delta = values - data[k]['d1_avg'][i][mask]\n",
    "            data[k]['d1_count'][i][mask] += 1\n",
    "            data[k]['d1_avg'][i][mask] += delta / data[k]['d1_count'][i][mask]\n",
    "            data[k]['d1_sec'][i][mask] += delta * (values - data[k]['d1_avg'][i][mask])\n",
    "            data[k]['d1_min'][i][mask] = np.minimum(data[k]['d1_min'][i][mask], values)\n",
    "            data[k]['d1_max'][i][mask] = np.maximum(data[k]['d1_max'][i][mask], values)\n",
    "\n",
    "            values = np.array(row['accuracies'])[j:j + l, d2_index]\n",
    "            mask = np.where(np.array(np.invert(np.isnan(values)), dtype=int))[0]\n",
    "            values = values[mask]\n",
    "            delta = values - data[k]['d2_avg'][i][mask]\n",
    "            data[k]['d2_count'][i][mask] += 1\n",
    "            data[k]['d2_avg'][i][mask] += delta / data[k]['d2_count'][i][mask]\n",
    "            data[k]['d2_sec'][i][mask] += delta * (values - data[k]['d2_avg'][i][mask])\n",
    "            data[k]['d2_min'][i][mask] = np.minimum(data[k]['d2_min'][i][mask], values)\n",
    "            data[k]['d2_max'][i][mask] = np.maximum(data[k]['d2_max'][i][mask], values)\n",
    "\n",
    "            j += l\n",
    "    data[k]['d1_sem'] = list()\n",
    "    data[k]['d2_sem'] = list()\n",
    "    for i in range(len(max_phase_lengths)):\n",
    "        data[k]['d1_sem'].append(np.nan_to_num(np.sqrt(data[k]['d1_sec'][i]) / data[k]['d1_count'][i]))\n",
    "        data[k]['d2_sem'].append(np.nan_to_num(np.sqrt(data[k]['d2_sec'][i]) / data[k]['d2_count'][i]))\n",
    "    del data[k]['d1_sec']\n",
    "    del data[k]['d2_sec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [E12, E34, E1234]\n",
    "phase_lengths = [{experiment: list() for experiment in experiments} for i in range(max([len(v) for v in experiments]))]\n",
    "for _, row in rdf.iterrows():\n",
    "    if row['phases'] not in experiments:\n",
    "        continue\n",
    "    for i in range(len(row['phases'])):\n",
    "        phase_lengths[i][row['phases']].append(row['phase_length'][i])\n",
    "\n",
    "text = ''\n",
    "text += '|------------|-------------------|------------------|------------------|------------------|\\n'\n",
    "text += '| Experiment | Steps in Phase 1  | Steps in Phase 2 | Steps in Phase 3 | Steps in Phase 4 |\\n'\n",
    "text += '|------------|-------------------|------------------|------------------|------------------|\\n'\n",
    "for experiment, experiment_name in zip(experiments, ['E12', 'E34', 'E1234']):\n",
    "    text += '| {0:>10} |   {1:>7.2f}+-{2:<4.2f}   |'.format(\n",
    "        experiment_name,\n",
    "        np.mean(phase_lengths[0][experiment]), np.std(phase_lengths[0][experiment]) / np.sqrt(len(phase_lengths[0][experiment])))\n",
    "    if experiment in [E12, E34]:\n",
    "        text += '   {0:>6.2f}+-{1:<4.2f}   |   {2:>5.2f}+-{3:<4.2f}    |   {4:>5.2f}+-{5:<4.2f}    |\\n'.format(\n",
    "            np.mean(phase_lengths[1][experiment]), np.std(phase_lengths[1][experiment]) / np.sqrt(len(phase_lengths[1][experiment])),\n",
    "            np.mean(phase_lengths[2][experiment]), np.std(phase_lengths[2][experiment]) / np.sqrt(len(phase_lengths[2][experiment])),\n",
    "            np.mean(phase_lengths[3][experiment]), np.std(phase_lengths[3][experiment]) / np.sqrt(len(phase_lengths[3][experiment])))\n",
    "    else:\n",
    "        assert(experiment == E1234)\n",
    "        text += '       N/A        |       N/A        |       N/A        |\\n'\n",
    "text += '|------------|-------------------|------------------|------------------|------------------|'\n",
    "with open('experiment_1_speed.txt', 'w') as outfile:\n",
    "    print(text, file=outfile)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [E12, E34]\n",
    "accuracies = {experiment: [[list() for j in range(2)] for i in range(4)] for experiment in experiments}\n",
    "for _, row in rdf.iterrows():\n",
    "    if row['phases'] not in experiments:\n",
    "        continue\n",
    "    for i in range(4):\n",
    "        for j in range(2):\n",
    "            accuracies[row['phases']][i][j].append(row['accuracies'][sum(row['phase_length'][:i + 1]) - 1][j])\n",
    "\n",
    "text = ''\n",
    "text += '|------------|-------|-------------------|-------------------|\\n'\n",
    "text += '| Experiment | Phase | Accuracy on 1 + 2 | Accuracy on 3 + 4 |\\n'\n",
    "text += '|------------|-------|-------------------|-------------------|\\n'\n",
    "for experiment, experiment_name in zip(experiments, ['E12', 'E34', 'E1234']):\n",
    "    for phase in range(4):\n",
    "        if (experiment != E12) and (phase == 0):\n",
    "            text += '|------------|-------|-------------------|-------------------|\\n'\n",
    "        text += '| {0:>10} |   {1}   |  {2:>6.4f}+-{3:<6.4f}   |  {4:>6.4f}+-{5:<6.4f}   |\\n'.format(\n",
    "            experiment_name if phase == 1 else '',\n",
    "            phase,\n",
    "            np.mean(accuracies[experiment][phase][0]), np.std(accuracies[experiment][phase][0]) / np.sqrt(len(accuracies[experiment][phase][0])),\n",
    "            np.mean(accuracies[experiment][phase][1]), np.std(accuracies[experiment][phase][1]) / np.sqrt(len(accuracies[experiment][phase][1])))\n",
    "text += '|------------|-------|-------------------|-------------------|\\n'\n",
    "with open('experiment_1_retention.txt', 'w') as outfile:\n",
    "    print(text, file=outfile)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [E12, E34]\n",
    "ratios = {experiment: list() for experiment in experiments}\n",
    "for _, row in rdf.iterrows():\n",
    "    if row['phases'] not in experiments:\n",
    "        continue\n",
    "    ratios[row['phases']].append(row['phase_length'][0] / row['phase_length'][2])\n",
    "\n",
    "text = ''\n",
    "text += '|------------|------------|\\n'\n",
    "text += '| Experiment | Relearning |\\n'\n",
    "text += '|------------|------------|\\n'\n",
    "for experiment, experiment_name in zip(experiments, ['E12', 'E34']):\n",
    "    text += '| {0:>10} | {1:>4.2f}+-{2:<4.2f} |\\n'.format(\n",
    "        experiment_name,\n",
    "        np.mean(ratios[experiment]),\n",
    "        np.std(ratios[experiment]) / np.sqrt(len(ratios[experiment])))\n",
    "text += '|------------|------------|\\n'\n",
    "with open('experiment_1_relearning.txt', 'w') as outfile:\n",
    "    print(text, file=outfile)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "threshold = 125\n",
    "fig = plt.figure(figsize=(7, 4.5), dpi=300)\n",
    "gs = GridSpec(3, 2, figure=fig)\n",
    "axarr = list()\n",
    "axarr.append(fig.add_subplot(gs[0, :]))\n",
    "axarr.append(fig.add_subplot(gs[1, 0]))\n",
    "axarr.append(fig.add_subplot(gs[2, 0]))\n",
    "axarr.append(fig.add_subplot(gs[2, 1]))\n",
    "colors = sns.color_palette('colorblind', len(data.keys()))\n",
    "xmax = 0\n",
    "\n",
    "# phase 1 plot\n",
    "ax = axarr[0]\n",
    "\n",
    "x = np.where(data[E1234]['d1_count'][0] >= threshold)[0]\n",
    "xmax = max(xmax, max(x))\n",
    "y = data[E1234]['d1_avg'][0][x]\n",
    "yerr = data[E1234]['d1_sem'][0][x]\n",
    "ax.fill_between(x, y - yerr, y + yerr, color=colors[2], alpha=0.1)\n",
    "ax.plot(x, y, color=colors[2], label=r'$D_{(1 + 2)}$ in $E_{(1, 2, 3, 4)}$', linestyle='--', linewidth=1)\n",
    "\n",
    "x = np.where(data[E1234]['d2_count'][0] >= threshold)[0]\n",
    "xmax = max(xmax, max(x))\n",
    "y = data[E1234]['d2_avg'][0][x]\n",
    "yerr = data[E1234]['d2_sem'][0][x]\n",
    "ax.fill_between(x, y - yerr, y + yerr, color=colors[2], alpha=0.1)\n",
    "ax.plot(x, y, color=colors[2], label=r'$D_{(3 + 4)}$ in $E_{(1, 2, 3, 4)}$', linestyle='-', linewidth=1)\n",
    "\n",
    "x = np.where(data[E12]['d1_count'][0] >= threshold)[0]\n",
    "xmax = max(xmax, max(x))\n",
    "y = data[E12]['d1_avg'][0][x]\n",
    "yerr = data[E12]['d1_sem'][0][x]\n",
    "ax.fill_between(x, y - yerr, y + yerr, color=colors[0], alpha=0.1)\n",
    "ax.plot(x, y, color=colors[0], label=r'$D_{(1 + 2)}$ in $E_{(1, 2)}$', linestyle='--', linewidth=1)\n",
    "\n",
    "x = np.where(data[E12]['d2_count'][0] >= threshold)[0]\n",
    "xmax = max(xmax, max(x))\n",
    "y = data[E12]['d2_avg'][0][x]\n",
    "yerr = data[E12]['d2_sem'][0][x]\n",
    "ax.fill_between(x, y - yerr, y + yerr, color=colors[0], alpha=0.1)\n",
    "ax.plot(x, y, color=colors[0], label=r'$D_{(3 + 4)}$ in $E_{(1, 2)}$', linestyle='-', linewidth=1)\n",
    "\n",
    "x = np.where(data[E34]['d1_count'][0] >= threshold)[0]\n",
    "xmax = max(xmax, max(x))\n",
    "y = data[E34]['d1_avg'][0][x]\n",
    "yerr = data[E34]['d1_sem'][0][x]\n",
    "ax.fill_between(x, y - yerr, y + yerr, color=colors[1], alpha=0.1)\n",
    "ax.plot(x, y, color=colors[1], label=r'$D_{(1 + 2)}$ in $E_{(3, 4)}$', linestyle='--', linewidth=1)\n",
    "\n",
    "x = np.where(data[E34]['d2_count'][0] >= threshold)[0]\n",
    "xmax = max(xmax, max(x))\n",
    "y = data[E34]['d2_avg'][0][x]\n",
    "yerr = data[E34]['d2_sem'][0][x]\n",
    "ax.fill_between(x, y - yerr, y + yerr, color=colors[1], alpha=0.1)\n",
    "ax.plot(x, y, color=colors[1], label=r'$D_{(3 + 4)}$ in $E_{(3, 4)}$', linestyle='-', linewidth=1)\n",
    "\n",
    "# phase 2 plot\n",
    "ax = axarr[1]\n",
    "\n",
    "x = np.where(data[E12]['d1_count'][1] >= threshold)[0]\n",
    "xmax = max(xmax, max(x))\n",
    "y = data[E12]['d1_avg'][1][x]\n",
    "yerr = data[E12]['d1_sem'][1][x]\n",
    "ax.fill_between(x, y - yerr, y + yerr, color=colors[0], alpha=0.1)\n",
    "ax.plot(x, y, color=colors[0], linestyle='--', linewidth=1)\n",
    "\n",
    "x = np.where(data[E12]['d2_count'][1] >= threshold)[0]\n",
    "xmax = max(xmax, max(x))\n",
    "y = data[E12]['d2_avg'][1][x]\n",
    "yerr = data[E12]['d2_sem'][1][x]\n",
    "ax.fill_between(x, y - yerr, y + yerr, color=colors[0], alpha=0.1)\n",
    "ax.plot(x, y, color=colors[0], linestyle='-', linewidth=1)\n",
    "\n",
    "x = np.where(data[E34]['d1_count'][1] >= threshold)[0]\n",
    "xmax = max(xmax, max(x))\n",
    "y = data[E34]['d1_avg'][1][x]\n",
    "yerr = data[E34]['d1_sem'][1][x]\n",
    "ax.fill_between(x, y - yerr, y + yerr, color=colors[1], alpha=0.1)\n",
    "ax.plot(x, y, color=colors[1], linestyle='--', linewidth=1)\n",
    "\n",
    "x = np.where(data[E34]['d2_count'][1] >= threshold)[0]\n",
    "xmax = max(xmax, max(x))\n",
    "y = data[E34]['d2_avg'][1][x]\n",
    "yerr = data[E34]['d2_sem'][1][x]\n",
    "ax.fill_between(x, y - yerr, y + yerr, color=colors[1], alpha=0.1)\n",
    "ax.plot(x, y, color=colors[1], linestyle='-', linewidth=1)\n",
    "\n",
    "# phase 3 plot\n",
    "ax = axarr[2]\n",
    "\n",
    "x = np.where(data[E12]['d1_count'][2] >= threshold)[0]\n",
    "xmax = max(xmax, max(x))\n",
    "y = data[E12]['d1_avg'][2][x]\n",
    "yerr = data[E12]['d1_sem'][2][x]\n",
    "ax.fill_between(x, y - yerr, y + yerr, color=colors[0], alpha=0.1)\n",
    "ax.plot(x, y, color=colors[0], linestyle='--', linewidth=1)\n",
    "\n",
    "x = np.where(data[E12]['d2_count'][2] >= threshold)[0]\n",
    "xmax = max(xmax, max(x))\n",
    "y = data[E12]['d2_avg'][2][x]\n",
    "yerr = data[E12]['d2_sem'][2][x]\n",
    "ax.fill_between(x, y - yerr, y + yerr, color=colors[0], alpha=0.1)\n",
    "ax.plot(x, y, color=colors[0], linestyle='-', linewidth=1)\n",
    "\n",
    "x = np.where(data[E34]['d1_count'][2] >= threshold)[0]\n",
    "xmax = max(xmax, max(x))\n",
    "y = data[E34]['d1_avg'][2][x]\n",
    "yerr = data[E34]['d1_sem'][2][x]\n",
    "ax.fill_between(x, y - yerr, y + yerr, color=colors[1], alpha=0.1)\n",
    "ax.plot(x, y, color=colors[1], linestyle='--', linewidth=1)\n",
    "\n",
    "x = np.where(data[E34]['d2_count'][2] >= threshold)[0]\n",
    "xmax = max(xmax, max(x))\n",
    "y = data[E34]['d2_avg'][2][x]\n",
    "yerr = data[E34]['d2_sem'][2][x]\n",
    "ax.fill_between(x, y - yerr, y + yerr, color=colors[1], alpha=0.1)\n",
    "ax.plot(x, y, color=colors[1], linestyle='-', linewidth=1)\n",
    "\n",
    "# phase 4 plot\n",
    "ax = axarr[3]\n",
    "\n",
    "x = np.where(data[E12]['d1_count'][3] >= threshold)[0]\n",
    "xmax = max(xmax, max(x))\n",
    "y = data[E12]['d1_avg'][3][x]\n",
    "yerr = data[E12]['d1_sem'][3][x]\n",
    "ax.fill_between(x, y - yerr, y + yerr, color=colors[0], alpha=0.1)\n",
    "ax.plot(x, y, color=colors[0], linestyle='--', linewidth=1)\n",
    "\n",
    "x = np.where(data[E12]['d2_count'][3] >= threshold)[0]\n",
    "xmax = max(xmax, max(x))\n",
    "y = data[E12]['d2_avg'][3][x]\n",
    "yerr = data[E12]['d2_sem'][3][x]\n",
    "ax.fill_between(x, y - yerr, y + yerr, color=colors[0], alpha=0.1)\n",
    "ax.plot(x, y, color=colors[0], linestyle='-', linewidth=1)\n",
    "\n",
    "x = np.where(data[E34]['d1_count'][3] >= threshold)[0]\n",
    "xmax = max(xmax, max(x))\n",
    "y = data[E34]['d1_avg'][3][x]\n",
    "yerr = data[E34]['d1_sem'][3][x]\n",
    "ax.fill_between(x, y - yerr, y + yerr, color=colors[1], alpha=0.1)\n",
    "ax.plot(x, y, color=colors[1], linestyle='--', linewidth=1)\n",
    "\n",
    "x = np.where(data[E34]['d2_count'][3] >= threshold)[0]\n",
    "xmax = max(xmax, max(x))\n",
    "y = data[E34]['d2_avg'][3][x]\n",
    "yerr = data[E34]['d2_sem'][3][x]\n",
    "ax.fill_between(x, y - yerr, y + yerr, color=colors[1], alpha=0.1)\n",
    "ax.plot(x, y, color=colors[1], linestyle='-', linewidth=1)\n",
    "\n",
    "# clean up plot\n",
    "for j in range(len(axarr)):\n",
    "    ax = axarr[j]\n",
    "    ax.set_ylim(-0.1, 1.1)\n",
    "    ax.set_yticks([0.0, 0.5, 1.0])\n",
    "    ax.set_xlabel(r'Steps', labelpad=X_LABEL_PAD)\n",
    "axarr[0].set_ylabel(r'Phase 1 Acc.', labelpad=Y_LABEL_PAD)\n",
    "axarr[0].set_xticks([0, 200, 400, 600, 800, 1000, 1200])\n",
    "axarr[0].set_xlim(0, max(xmax * 1.01, 1200))\n",
    "axarr[1].set_ylabel(r'Phase 2 Acc.', labelpad=Y_LABEL_PAD)\n",
    "axarr[1].set_xticks([0, 100, 200])\n",
    "axarr[1].set_xlim(0, 200)\n",
    "axarr[2].set_ylabel(r'Phase 3 Acc.', labelpad=Y_LABEL_PAD)\n",
    "axarr[2].set_xticks([0, 100, 200])\n",
    "axarr[2].set_xlim(0, 200)\n",
    "axarr[3].set_ylabel(r'Phase 4 Acc.', labelpad=Y_LABEL_PAD)\n",
    "axarr[3].set_xticks([0, 100, 200])\n",
    "axarr[3].set_xlim(0, 200)\n",
    "fig.tight_layout()\n",
    "y0 = axarr[1].get_position().y0\n",
    "y1 = axarr[1].get_position().y1\n",
    "x0 = axarr[3].get_position().x0\n",
    "x1 = axarr[3].get_position().x1\n",
    "fig.legend(bbox_to_anchor=(x0 + (x1 - x0) / 2, y1), loc='upper center')\n",
    "\n",
    "# save plot\n",
    "fig.savefig('experiment_1_accuracies.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "text += '|-------|---------------|\\n'\n",
    "text += '| Phase | Steps         |\\n'\n",
    "text += '|-------|---------------|\\n'\n",
    "for i, phase_lengths in enumerate(data[ER]['phase_lengths']):\n",
    "    text += '| {0:>5} | {1:>7.2f}+-{2:4.2f} |\\n'.format(\n",
    "        i + 1,\n",
    "        np.mean(phase_lengths),\n",
    "        np.std(phase_lengths) / np.sqrt(len(phase_lengths)))\n",
    "text += '|-------|---------------|\\n'\n",
    "with open('experiment_1_extended_phase_lengths.txt', 'w') as outfile:\n",
    "    print(text, file=outfile)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=#top>Back to Top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2 MNIST<a name='experiment_2_mnist'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Phase<a name='experiment_2_mnist_validation'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = mnist_tools.load_data(['experiment_2_mnist_validation.json'])\n",
    "rdf = rdf[rdf['success']]\n",
    "for i in rdf.index:\n",
    "    if rdf.at[i, 'optimizer'] == 'sgd':\n",
    "        if float(rdf.at[i, 'momentum']) > 0:\n",
    "            rdf.at[i, 'optimizer'] = 'momentum'\n",
    "        else:\n",
    "            rdf.at[i, 'momentum'] = np.nan\n",
    "\n",
    "metric = mnist_tools.total_time_metric(50, 2500)\n",
    "best = mnist_tools.get_best(\n",
    "    mnist_tools.get_summary(rdf),\n",
    "    metric,\n",
    "    ['optimizer', 'momentum', 'rho'])\n",
    "key = ('sgd',)\n",
    "print('{0}: lr={1}, metric={2:.2f}, count={3}'.format(\n",
    "    optimizer_nice_names[key[0]],\n",
    "    best[key]['lr'],\n",
    "    metric(best[key]),\n",
    "    int(best[key]['count'][0])))\n",
    "for momentum in np.sort(rdf['momentum'].unique()):\n",
    "    key = ('momentum', momentum)\n",
    "    if key not in best:\n",
    "        continue\n",
    "    print('{0} momentum={1}: lr={2}, metric={3:.2f}, count={4}'.format(\n",
    "        optimizer_nice_names[key[0]],\n",
    "        momentum,\n",
    "        best[key]['lr'],\n",
    "        metric(best[key]),\n",
    "        int(best[key]['count'][0])))\n",
    "for rho in np.sort(rdf['rho'].unique()):\n",
    "    key = ('rms', rho)\n",
    "    if key not in best:\n",
    "        continue\n",
    "    print('{0} rho={1}: lr={2}, metric={3:.2f}, count={4}'.format(\n",
    "        optimizer_nice_names[key[0]],\n",
    "        rho,\n",
    "        best[key]['lr'],\n",
    "        metric(best[key]),\n",
    "        int(best[key]['count'][0])))\n",
    "key = ('adam',)\n",
    "print('{0} beta_1={1} beta_2={2}: lr={3}, metric={4:.2f}, count={5}'.format(\n",
    "    optimizer_nice_names[key[0]],\n",
    "    best[key]['beta_1'],\n",
    "    best[key]['beta_2'],\n",
    "    best[key]['lr'],\n",
    "    metric(best[key]),\n",
    "    int(best[key]['count'][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = mnist_tools.get_best(\n",
    "    mnist_tools.get_summary(rdf),\n",
    "    metric,\n",
    "    ['optimizer', 'lr', 'momentum', 'rho'])\n",
    "summary = dict()\n",
    "for k, v in best.items():\n",
    "    if (k[0] == 'momentum') and (k[2] != 0.9):\n",
    "        continue\n",
    "    if (k[0] == 'rms') and (k[2] != 0.999):\n",
    "        continue\n",
    "    if k[0] not in summary:\n",
    "        summary[k[0]] = dict()\n",
    "    assert(k[1] not in summary[k[0]])\n",
    "    summary[k[0]][k[1]] = v\n",
    "\n",
    "max_phase_lengths = list()\n",
    "for _, row in rdf.iterrows():\n",
    "    for i, l in enumerate(row['phase_length']):\n",
    "        if len(max_phase_lengths) == i:\n",
    "            max_phase_lengths.append(0)\n",
    "        max_phase_lengths[i] = max(max_phase_lengths[i], l)\n",
    "data = dict()\n",
    "for k in best.keys():\n",
    "    data[k] = dict()\n",
    "    for k2 in ['d1_count',\n",
    "               'd2_count',\n",
    "               'online_count',\n",
    "               'as_count',\n",
    "               'pi_count']:\n",
    "        data[k][k2] = [np.zeros(i, dtype=int) for i in max_phase_lengths]\n",
    "    for k2 in ['d1_avg',\n",
    "               'd1_sec',\n",
    "               'd1_min',\n",
    "               'd1_max',\n",
    "               'd2_avg',\n",
    "               'd2_sec',\n",
    "               'd2_min',\n",
    "               'd2_max',\n",
    "               'online_avg',\n",
    "               'online_sec',\n",
    "               'online_min',\n",
    "               'online_max',\n",
    "               'as_avg',\n",
    "               'as_sec',\n",
    "               'as_min',\n",
    "               'as_max',\n",
    "               'pi_avg',\n",
    "               'pi_sec',\n",
    "               'pi_min',\n",
    "               'pi_max']:\n",
    "        data[k][k2] = [np.zeros(i, dtype=float) for i in max_phase_lengths]\n",
    "    for k2 in ['d1_final_avg',\n",
    "               'd1_final_sec',\n",
    "               'd2_final_avg',\n",
    "               'd2_final_sec',\n",
    "               'online_final_avg',\n",
    "               'online_final_sec',\n",
    "               'as_final_avg',\n",
    "               'as_final_sec',\n",
    "               'pi_final_avg',\n",
    "               'pi_final_sec']:\n",
    "        data[k][k2] = [0 for _ in range(len(max_phase_lengths))]\n",
    "    data[k]['phase_length_count'] = [0 for i in max_phase_lengths]\n",
    "    data[k]['phase_length_avg'] = [0 for i in max_phase_lengths]\n",
    "    data[k]['phase_length_sec'] = [0 for i in max_phase_lengths]\n",
    "    for i in range(len(max_phase_lengths)):\n",
    "        data[k]['d1_min'][i] += 1\n",
    "        data[k]['d2_min'][i] += 1\n",
    "    kdf = rdf[rdf['optimizer'] == k[0]]\n",
    "    kdf = kdf[kdf['lr'] == k[1]]\n",
    "    if k[0] == 'momentum':\n",
    "        kdf = kdf[kdf['momentum'] == k[2]]\n",
    "    if k[0] == 'rms':\n",
    "        kdf = kdf[kdf['rho'] == k[2]]\n",
    "    for _, row in kdf.iterrows():\n",
    "        j = 0\n",
    "        for i, l in enumerate(row['phase_length']):\n",
    "            delta = l - data[k]['phase_length_avg'][i]\n",
    "            data[k]['phase_length_count'][i] += 1\n",
    "            data[k]['phase_length_avg'][i] += delta / data[k]['phase_length_count'][i]\n",
    "            data[k]['phase_length_sec'][i] += delta * (l - data[k]['phase_length_avg'][i])\n",
    "\n",
    "            values = np.array(row['accuracies'])[j:j + l, 0]\n",
    "            mask = np.where(np.array(np.invert(np.isnan(values)), dtype=int))[0]\n",
    "            values = values[mask]\n",
    "            delta = values - data[k]['d1_avg'][i][mask]\n",
    "            data[k]['d1_count'][i][mask] += 1\n",
    "            data[k]['d1_avg'][i][mask] += delta / data[k]['d1_count'][i][mask]\n",
    "            data[k]['d1_sec'][i][mask] += delta * (values - data[k]['d1_avg'][i][mask])\n",
    "            data[k]['d1_min'][i][mask] = np.minimum(data[k]['d1_min'][i][mask], values)\n",
    "            data[k]['d1_max'][i][mask] = np.maximum(data[k]['d1_max'][i][mask], values)\n",
    "            delta = values[-1] - data[k]['d1_final_avg'][i]\n",
    "            data[k]['d1_final_avg'][i] += delta / data[k]['d1_count'][i][0]\n",
    "            data[k]['d1_final_sec'][i] += delta * (values[-1] - data[k]['d1_final_avg'][i])\n",
    "\n",
    "            values = np.array(row['accuracies'])[j:j + l, 1]\n",
    "            mask = np.where(np.array(np.invert(np.isnan(values)), dtype=int))[0]\n",
    "            values = values[mask]\n",
    "            delta = values - data[k]['d2_avg'][i][mask]\n",
    "            data[k]['d2_count'][i][mask] += 1\n",
    "            data[k]['d2_avg'][i][mask] += delta / data[k]['d2_count'][i][mask]\n",
    "            data[k]['d2_sec'][i][mask] += delta * (values - data[k]['d2_avg'][i][mask])\n",
    "            data[k]['d2_min'][i][mask] = np.minimum(data[k]['d2_min'][i][mask], values)\n",
    "            data[k]['d2_max'][i][mask] = np.maximum(data[k]['d2_max'][i][mask], values)\n",
    "            delta = values[-1] - data[k]['d2_final_avg'][i]\n",
    "            data[k]['d2_final_avg'][i] += delta / data[k]['d2_count'][i][0]\n",
    "            data[k]['d2_final_sec'][i] += delta * (values[-1] - data[k]['d2_final_avg'][i])\n",
    "\n",
    "            values = np.cumsum(np.array(row['correct'])[j:j + l]) / (np.arange(l) + 1)\n",
    "            mask = np.where(np.array(np.invert(np.isnan(values)), dtype=int))[0]\n",
    "            values = values[mask]\n",
    "            delta = values - data[k]['online_avg'][i][mask]\n",
    "            data[k]['online_count'][i][mask] += 1\n",
    "            data[k]['online_avg'][i][mask] += delta / data[k]['online_count'][i][mask]\n",
    "            data[k]['online_sec'][i][mask] += delta * (values - data[k]['online_avg'][i][mask])\n",
    "            data[k]['online_min'][i][mask] = np.minimum(data[k]['online_min'][i][mask], values)\n",
    "            data[k]['online_max'][i][mask] = np.maximum(data[k]['online_max'][i][mask], values)\n",
    "            delta = values[-1] - data[k]['online_final_avg'][i]\n",
    "            data[k]['online_final_avg'][i] += delta / data[k]['online_count'][i][0]\n",
    "            data[k]['online_final_sec'][i] += delta * (values[-1] - data[k]['online_final_avg'][i])\n",
    "\n",
    "            values = np.array(row['activation_similarity'])[j:j + l]\n",
    "            mask = np.where(np.array(np.invert(np.isnan(values)), dtype=int))[0]\n",
    "            values = values[mask]\n",
    "            delta = values - data[k]['as_avg'][i][mask]\n",
    "            data[k]['as_count'][i][mask] += 1\n",
    "            data[k]['as_avg'][i][mask] += delta / data[k]['as_count'][i][mask]\n",
    "            data[k]['as_sec'][i][mask] += delta * (values - data[k]['as_avg'][i][mask])\n",
    "            data[k]['as_min'][i][mask] = np.minimum(data[k]['as_min'][i][mask], values)\n",
    "            data[k]['as_max'][i][mask] = np.maximum(data[k]['as_max'][i][mask], values)\n",
    "            delta = values[-1] - data[k]['as_final_avg'][i]\n",
    "            data[k]['as_final_avg'][i] += delta / data[k]['as_count'][i][0]\n",
    "            data[k]['as_final_sec'][i] += delta * (values[-1] - data[k]['as_final_avg'][i])\n",
    "\n",
    "            values = np.array(row['pairwise_interference'])[j:j + l]\n",
    "            mask = np.where(np.array(np.invert(np.isnan(values)), dtype=int))[0]\n",
    "            values = values[mask]\n",
    "            delta = values - data[k]['pi_avg'][i][mask]\n",
    "            data[k]['pi_count'][i][mask] += 1\n",
    "            data[k]['pi_avg'][i][mask] += delta / data[k]['pi_count'][i][mask]\n",
    "            data[k]['pi_sec'][i][mask] += delta * (values - data[k]['pi_avg'][i][mask])\n",
    "            data[k]['pi_min'][i][mask] = np.minimum(data[k]['pi_min'][i][mask], values)\n",
    "            data[k]['pi_max'][i][mask] = np.maximum(data[k]['pi_max'][i][mask], values)\n",
    "            delta = values[-1] - data[k]['pi_final_avg'][i]\n",
    "            data[k]['pi_final_avg'][i] += delta / data[k]['pi_count'][i][0]\n",
    "            data[k]['pi_final_sec'][i] += delta * (values[-1] - data[k]['pi_final_avg'][i])\n",
    "\n",
    "            j += l\n",
    "    data[k]['phase_length_sem'] = list()\n",
    "    data[k]['d1_sem'] = list()\n",
    "    data[k]['d2_sem'] = list()\n",
    "    data[k]['online_sem'] = list()\n",
    "    data[k]['as_sem'] = list()\n",
    "    data[k]['pi_sem'] = list()\n",
    "    data[k]['d1_final_sem'] = list()\n",
    "    data[k]['d2_final_sem'] = list()\n",
    "    data[k]['online_final_sem'] = list()\n",
    "    data[k]['as_final_sem'] = list()\n",
    "    data[k]['pi_final_sem'] = list()\n",
    "    for i in range(len(max_phase_lengths)):\n",
    "        data[k]['phase_length_sem'].append(np.sqrt(data[k]['phase_length_sec'][i]) / data[k]['phase_length_count'][i])\n",
    "        data[k]['d1_sem'].append(np.nan_to_num(np.sqrt(data[k]['d1_sec'][i]) / data[k]['d1_count'][i]))\n",
    "        data[k]['d2_sem'].append(np.nan_to_num(np.sqrt(data[k]['d2_sec'][i]) / data[k]['d2_count'][i]))\n",
    "        data[k]['online_sem'].append(np.nan_to_num(np.sqrt(data[k]['online_sec'][i]) / data[k]['online_count'][i]))\n",
    "        data[k]['as_sem'].append(np.nan_to_num(np.sqrt(data[k]['as_sec'][i]) / data[k]['as_count'][i]))\n",
    "        data[k]['pi_sem'].append(np.nan_to_num(np.sqrt(data[k]['pi_sec'][i]) / data[k]['pi_count'][i]))\n",
    "        data[k]['d1_final_sem'].append(np.nan_to_num(np.sqrt(data[k]['d1_final_sec'][i]) / data[k]['d1_count'][i][0]))\n",
    "        data[k]['d2_final_sem'].append(np.nan_to_num(np.sqrt(data[k]['d2_final_sec'][i]) / data[k]['d2_count'][i][0]))\n",
    "        data[k]['online_final_sem'].append(np.nan_to_num(np.sqrt(data[k]['online_final_sec'][i]) / data[k]['online_count'][i][0]))\n",
    "        data[k]['as_final_sem'].append(np.nan_to_num(np.sqrt(data[k]['as_final_sec'][i]) / data[k]['as_count'][i][0]))\n",
    "        data[k]['pi_final_sem'].append(np.nan_to_num(np.sqrt(data[k]['pi_final_sec'][i]) / data[k]['pi_count'][i][0]))\n",
    "\n",
    "    del data[k]['phase_length_sec']\n",
    "    del data[k]['d1_sec']\n",
    "    del data[k]['d2_sec']\n",
    "    del data[k]['online_sec']\n",
    "    del data[k]['as_sec']\n",
    "    del data[k]['pi_sec']\n",
    "    del data[k]['d1_final_sec']\n",
    "    del data[k]['d2_final_sec']\n",
    "    del data[k]['online_final_sec']\n",
    "    del data[k]['as_final_sec']\n",
    "    del data[k]['pi_final_sec']\n",
    "\n",
    "collected = {k[0]: dict() for k in data.keys()}\n",
    "for k, v in data.items():\n",
    "    if (k[0] == 'momentum') and (k[2] != 0.9):\n",
    "        continue\n",
    "    if (k[0] == 'rms') and (k[2] != 0.999):\n",
    "        continue\n",
    "    collected[k[0]][k[1]] = v\n",
    "ordered = {k: dict() for k in collected.keys()}\n",
    "for k, v in collected.items():\n",
    "    ordered[k]['lr'] = sorted(v.keys())\n",
    "    for k2 in ['phase_length',\n",
    "               'd1_final',\n",
    "               'd2_final',\n",
    "               'online_final',\n",
    "               'as_final',\n",
    "               'pi_final']:\n",
    "        ordered[k][k2 + '_avg'] = list()\n",
    "        ordered[k][k2 + '_sem'] = list()\n",
    "    for lr in ordered[k]['lr']:\n",
    "        for k2 in ['phase_length',\n",
    "                   'd1_final',\n",
    "                   'd2_final',\n",
    "                   'online_final',\n",
    "                   'as_final',\n",
    "                   'pi_final']:\n",
    "            ordered[k][k2 + '_avg'].append(collected[k][lr][k2 + '_avg'])\n",
    "            ordered[k][k2 + '_sem'].append(collected[k][lr][k2 + '_sem'])\n",
    "    for k2 in ['phase_length','d1_final',\n",
    "               'd2_final',\n",
    "               'online_final',\n",
    "               'as_final',\n",
    "               'pi_final']:\n",
    "        ordered[k][k2 + '_avg'] = np.array(ordered[k][k2 + '_avg'])\n",
    "        ordered[k][k2 + '_sem'] = np.array(ordered[k][k2 + '_sem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axmat = plt.subplots(4, 2, figsize=(5.5, 5.5), dpi=300, sharex=True)\n",
    "colors = sns.color_palette('colorblind', len(ordered.keys()))\n",
    "xmax = 0\n",
    "for j in range(4):\n",
    "    for i, (k, v) in enumerate(sorted(ordered.items(), key=lambda x: x[0])):\n",
    "        label = optimizer_nice_names[k] if j == 0 else None\n",
    "        other_phase = (j + 1) % 2 + 1\n",
    "        x = v['lr']\n",
    "        y = v['d{}_final_avg'.format(other_phase)][:, j]\n",
    "        yerr = v['d{}_final_sem'.format(other_phase)][:, j]\n",
    "        axmat[j, 0].plot(\n",
    "            x,\n",
    "            y,\n",
    "            '-o',\n",
    "            linestyle='--',\n",
    "            linewidth=1,\n",
    "            markersize=2,\n",
    "            color=colors[i])\n",
    "        axmat[j, 0].fill_between(\n",
    "            x,\n",
    "            y - yerr,\n",
    "            y + yerr,\n",
    "            color=colors[i],\n",
    "            alpha=0.3)\n",
    "\n",
    "        y = v['online_final_avg'][:, j]\n",
    "        yerr = v['online_final_sem'][:, j]\n",
    "        axmat[j, 0].plot(\n",
    "            x,\n",
    "            y,\n",
    "            '-o',\n",
    "            label=label,\n",
    "            linewidth=1,\n",
    "            markersize=2,\n",
    "            color=colors[i])\n",
    "        axmat[j, 0].fill_between(\n",
    "            x,\n",
    "            y - yerr,\n",
    "            y + yerr,\n",
    "            color=colors[i],\n",
    "            alpha=0.3)\n",
    "\n",
    "        y = v['phase_length_avg'][:, j]\n",
    "        yerr = v['phase_length_avg'][:, j]\n",
    "        axmat[j, 1].plot(\n",
    "            x,\n",
    "            y,\n",
    "            '-o',\n",
    "            linewidth=1,\n",
    "            markersize=2,\n",
    "            color=colors[i])\n",
    "        axmat[j, 1].fill_between(\n",
    "            x,\n",
    "            y - yerr,\n",
    "            y + yerr,\n",
    "            color=colors[i],\n",
    "            alpha=0.3)\n",
    "\n",
    "for j in range(4):\n",
    "    axmat[j, 0].set_ylim(-0.05, 1.05)\n",
    "    axmat[j, 0].set_yticks([0.0, 0.5, 1.0])\n",
    "    axmat[j, 0].set_ylabel('Phase {}'.format(j + 1), labelpad=Y_LABEL_PAD)\n",
    "    axmat[j, 1].set_ylim(- 225, 4500)\n",
    "    axmat[j, 1].set_yticks([0, 2000, 4000])\n",
    "axmat[0, 0].set_title('Final Accuracy')\n",
    "axmat[0, 1].set_title('Steps in Phase')\n",
    "axmat[-1, 0].set_xscale('log', basex=2)\n",
    "axmat[-1, 0].set_xticks([2 ** (-18), 2 ** (-13), 2 ** (-8), 2 ** (-3)])\n",
    "axmat[-1, 0].set_xlim(2 ** (-18), 2 ** (-3))\n",
    "axmat[-1, 0].set_xlabel('Step-size', labelpad=X_LABEL_PAD)\n",
    "axmat[-1, 1].set_xlabel('Step-size', labelpad=X_LABEL_PAD)\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(hspace=0.15, wspace=0.3, right=0.775)\n",
    "pos = axmat[0, 0].get_position()\n",
    "fig.legend(bbox_to_anchor=(1, pos.y0 + (pos.y1 - pos.y0) / 2), loc='center right')\n",
    "fig.savefig('experiment_2_mnist_accuracies_and_speed_step-size.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.125,\n",
    "                  0.0625,\n",
    "                  0.03125,\n",
    "                  0.015625,\n",
    "                  0.0078125,\n",
    "                  0.00390625,\n",
    "                  0.001953125,\n",
    "                  0.0009765625,\n",
    "                  0.00048828125,\n",
    "                  0.000244140625,\n",
    "                  0.0001220703125,\n",
    "                  6.103515625e-05,\n",
    "                  3.0517578125e-05,\n",
    "                  1.52587890625e-05,\n",
    "                  7.62939453125e-06,\n",
    "                  3.814697265625e-06]\n",
    "\n",
    "retention = dict()\n",
    "relearning = dict()\n",
    "for _, row in rdf.iterrows():\n",
    "    optimizer = row['optimizer']\n",
    "    if optimizer == 'constant':\n",
    "        continue\n",
    "    if (optimizer == 'momentum') and (row['momentum'] != 0.9):\n",
    "        continue\n",
    "    if (optimizer == 'rms') and (row['rho'] != 0.999):\n",
    "        continue\n",
    "    lr = row['lr']\n",
    "    if optimizer not in retention:\n",
    "        assert(optimizer not in relearning)\n",
    "        for dict_ in [retention, relearning]:\n",
    "            dict_[optimizer] = collections.OrderedDict()\n",
    "            for value in learning_rates:\n",
    "                dict_[optimizer][value] = list()\n",
    "    retention[optimizer][lr].append(row['accuracies'][sum(row['phase_length'][:2]) - 1][0])\n",
    "    relearning[optimizer][lr].append(row['phase_length'][0] / row['phase_length'][2])\n",
    "\n",
    "colors = sns.color_palette(n_colors=len(retention.keys()))\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, dpi=300, figsize=(5.5, 1.85))\n",
    "sort_key = lambda x: x[0]\n",
    "for i, optimizer in enumerate(sorted(retention.keys())):\n",
    "    x = list(retention[optimizer].keys())\n",
    "    y1 = list()\n",
    "    y1err = list()\n",
    "    y2 = list()\n",
    "    y2err = list()\n",
    "    for lr in x:\n",
    "        for values, y, yerr in [(retention[optimizer][lr], y1, y1err),\n",
    "                                (relearning[optimizer][lr], y2, y2err)]:\n",
    "            y.append(np.mean(values))\n",
    "            yerr.append(np.std(values) / np.sqrt(len(values)))\n",
    "    x = np.array(x)\n",
    "    y1 = np.array(y1)\n",
    "    y1err = np.array(y1err)\n",
    "    y2 = np.array(y2)\n",
    "    y2err = np.array(y2err)\n",
    "\n",
    "    ax1.plot(\n",
    "        x,\n",
    "        y1,\n",
    "        '-o',\n",
    "        label=optimizer_nice_names[optimizer],\n",
    "        markersize=2,\n",
    "        linewidth=1,\n",
    "        color=colors[i])\n",
    "    ax1.fill_between(\n",
    "        x,\n",
    "        y1 - y1err,\n",
    "        y1 + y1err,\n",
    "        alpha=0.3,\n",
    "        color=colors[i])\n",
    "\n",
    "    ax2.plot(\n",
    "        x,\n",
    "        y2,\n",
    "        '-o',\n",
    "        linewidth=1,\n",
    "        markersize=2,\n",
    "        color=colors[i])\n",
    "    ax2.fill_between(\n",
    "        x,\n",
    "        y2 - y2err,\n",
    "        y2 + y2err,\n",
    "        alpha=0.3,\n",
    "        color=colors[i])\n",
    "\n",
    "for ax in [ax1, ax2]:\n",
    "    ax.set_xscale('log', basex=2)\n",
    "    ax.set_xlim(2 ** (-18), 2 ** (-3))\n",
    "    ax.set_xticks([2 ** (-15), 2 ** (-10), 2 ** (-5)])\n",
    "    ax.set_xlabel('Step-size', labelpad=X_LABEL_PAD)\n",
    "ax1.set_ylabel('Retention', labelpad=Y_LABEL_PAD)\n",
    "ax1.set_ylim(-0.05, 1.05)\n",
    "ax1.set_yticks([0.0, 0.5, 1.0])\n",
    "ax2.set_ylabel('Relearning', labelpad=Y_LABEL_PAD)\n",
    "ax2.set_ylim(-0.25, 4.75)\n",
    "ax2.set_yticks([0, 2, 4])\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(hspace=0.15, wspace=0.4, right=0.765)\n",
    "pos = ax1.get_position()\n",
    "fig.legend(bbox_to_anchor=(1, pos.y0 + (pos.y1 - pos.y0) / 2), loc='center right')\n",
    "fig.savefig('experiment_2_mnist_interference_step-size.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "threshold = 125\n",
    "fig, axmat = plt.subplots(2, 4, sharex=True, dpi=300, figsize=(5.5, 3))\n",
    "colors = sns.color_palette('colorblind', len(data.keys()))\n",
    "xmax = 0\n",
    "for j in range(4):\n",
    "    for i, (k, v) in enumerate(sorted(ordered.items(), key=lambda x: x[0])):\n",
    "        x = v['lr']\n",
    "        label = optimizer_nice_names[k] if j == 0 else None\n",
    "        y = v['as_final_avg'][:, j]\n",
    "        yerr = v['as_final_sem'][:, j]\n",
    "        axmat[0, j].plot(\n",
    "            x,\n",
    "            y,\n",
    "            '-o',\n",
    "            label=label,\n",
    "            linewidth=1,\n",
    "            markersize=2,\n",
    "            color=colors[i])\n",
    "        axmat[0, j].fill_between(\n",
    "            x,\n",
    "            y - yerr,\n",
    "            y + yerr,\n",
    "            color=colors[i],\n",
    "            alpha=0.3)\n",
    "\n",
    "        y = v['pi_final_avg'][:, j]\n",
    "        yerr = v['pi_final_sem'][:, j]\n",
    "        axmat[1, j].plot(\n",
    "            x,\n",
    "            y,\n",
    "            '-o',\n",
    "            linewidth=1,\n",
    "            markersize=2,\n",
    "            color=colors[i])\n",
    "        axmat[1, j].fill_between(\n",
    "            x,\n",
    "            y - yerr,\n",
    "            y + yerr,\n",
    "            color=colors[i],\n",
    "            alpha=0.3)\n",
    "\n",
    "axmat[0, 0].set_ylabel('Final Activation\\nSimilarity', labelpad=Y_LABEL_PAD)\n",
    "axmat[1, 0].set_ylabel('Final Pairwise\\nInterference', labelpad=Y_LABEL_PAD)\n",
    "for j in range(4):\n",
    "    axmat[0, j].set_title('Phase {}'.format(j + 1))\n",
    "    axmat[0, j].set_ylim(- 100, 1400)\n",
    "    axmat[0, j].set_yticks([0, 500, 1000])\n",
    "    axmat[1, j].set_ylim(- 0.5, 0.6)\n",
    "    axmat[1, j].set_yticks([- 0.3, 0, 0.3])\n",
    "    for i in range(2):\n",
    "        axmat[i, j].set_xscale('log', basex=2)\n",
    "        axmat[i, j].set_xlim(2 ** (-18), 2 ** (-3))\n",
    "        if j != 0:\n",
    "            axmat[i, j].tick_params(axis='y', which='both', left=False)\n",
    "            axmat[i, j].set_yticklabels([])\n",
    "    axmat[1, j].set_xticks([2 ** (-15), 2 ** (-10), 2 ** (-5)])\n",
    "    axmat[1, j].set_xlabel('Step-size', labelpad=X_LABEL_PAD)\n",
    "fig.align_ylabels(axmat[:, 0])\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(hspace=0.0, wspace=0.0, right=0.775)\n",
    "pos = axmat[0, 0].get_position()\n",
    "fig.legend(bbox_to_anchor=(1, pos.y0 + (pos.y1 - pos.y0) / 2), loc='center right')\n",
    "fig.savefig('experiment_2_mnist_additional_interference_step-size.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=#top>Back to Top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Phase<a name='experiment_2_mnist_testing'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = mnist_tools.load_data(['experiment_2_mnist_test.json'])\n",
    "rdf = rdf[rdf['success']]\n",
    "for i in rdf.index:\n",
    "    if rdf.at[i, 'optimizer'] == 'sgd':\n",
    "        if float(rdf.at[i, 'momentum']) > 0:\n",
    "            rdf.at[i, 'optimizer'] = 'momentum'\n",
    "        else:\n",
    "            rdf.at[i, 'momentum'] = None\n",
    "best = mnist_tools.get_best(\n",
    "    mnist_tools.get_summary(rdf),\n",
    "    mnist_tools.total_time_metric(50, 2500),\n",
    "    ['optimizer', 'momentum', 'rho'])\n",
    "\n",
    "max_phase_lengths = list()\n",
    "for _, row in rdf.iterrows():\n",
    "    for i, l in enumerate(row['phase_length']):\n",
    "        if len(max_phase_lengths) == i:\n",
    "            max_phase_lengths.append(0)\n",
    "        max_phase_lengths[i] = max(max_phase_lengths[i], l)\n",
    "data = dict()\n",
    "for k in best.keys():\n",
    "    data[k] = dict()\n",
    "    for k2 in ['d1_count',\n",
    "               'd2_count',\n",
    "               'online_count',\n",
    "               'as_count',\n",
    "               'pi_count']:\n",
    "        data[k][k2] = [np.zeros(i, dtype=int) for i in max_phase_lengths]\n",
    "    for k2 in ['d1_avg',\n",
    "               'd1_sec',\n",
    "               'd1_min',\n",
    "               'd1_max',\n",
    "               'd2_avg',\n",
    "               'd2_sec',\n",
    "               'd2_min',\n",
    "               'd2_max',\n",
    "               'online_avg',\n",
    "               'online_sec',\n",
    "               'online_min',\n",
    "               'online_max',\n",
    "               'as_avg',\n",
    "               'as_sec',\n",
    "               'as_min',\n",
    "               'as_max',\n",
    "               'pi_avg',\n",
    "               'pi_sec',\n",
    "               'pi_min',\n",
    "               'pi_max']:\n",
    "        data[k][k2] = [np.zeros(i, dtype=float) for i in max_phase_lengths]\n",
    "    data[k]['phase_lengths'] = [list() for i in max_phase_lengths]\n",
    "    for i in range(len(max_phase_lengths)):\n",
    "        data[k]['d1_min'][i] += 1\n",
    "        data[k]['d2_min'][i] += 1\n",
    "    kdf = rdf[rdf['optimizer'] == k[0]]\n",
    "    if k[0] == 'momentum':\n",
    "        kdf = kdf[kdf['momentum'] == k[1]]\n",
    "    if k[0] == 'rms':\n",
    "        kdf = kdf[kdf['rho'] == k[1]]\n",
    "    for _, row in kdf.iterrows():\n",
    "        j = 0\n",
    "        for i, l in enumerate(row['phase_length']):\n",
    "            data[k]['phase_lengths'][i].append(l)\n",
    "\n",
    "            values = np.array(row['accuracies'])[j:j + l, 0]\n",
    "            mask = np.where(np.array(np.invert(np.isnan(values)), dtype=int))[0]\n",
    "            values = values[mask]\n",
    "            delta = values - data[k]['d1_avg'][i][mask]\n",
    "            data[k]['d1_count'][i][mask] += 1\n",
    "            data[k]['d1_avg'][i][mask] += delta / data[k]['d1_count'][i][mask]\n",
    "            data[k]['d1_sec'][i][mask] += delta * (values - data[k]['d1_avg'][i][mask])\n",
    "            data[k]['d1_min'][i][mask] = np.minimum(data[k]['d1_min'][i][mask], values)\n",
    "            data[k]['d1_max'][i][mask] = np.maximum(data[k]['d1_max'][i][mask], values)\n",
    "\n",
    "            values = np.array(row['accuracies'])[j:j + l, 1]\n",
    "            mask = np.where(np.array(np.invert(np.isnan(values)), dtype=int))[0]\n",
    "            values = values[mask]\n",
    "            delta = values - data[k]['d2_avg'][i][mask]\n",
    "            data[k]['d2_count'][i][mask] += 1\n",
    "            data[k]['d2_avg'][i][mask] += delta / data[k]['d2_count'][i][mask]\n",
    "            data[k]['d2_sec'][i][mask] += delta * (values - data[k]['d2_avg'][i][mask])\n",
    "            data[k]['d2_min'][i][mask] = np.minimum(data[k]['d2_min'][i][mask], values)\n",
    "            data[k]['d2_max'][i][mask] = np.maximum(data[k]['d2_max'][i][mask], values)\n",
    "\n",
    "            values = np.cumsum(np.array(row['correct'])[j:j + l]) / (np.arange(l) + 1)\n",
    "            mask = np.where(np.array(np.invert(np.isnan(values)), dtype=int))[0]\n",
    "            values = values[mask]\n",
    "            delta = values - data[k]['online_avg'][i][mask]\n",
    "            data[k]['online_count'][i][mask] += 1\n",
    "            data[k]['online_avg'][i][mask] += delta / data[k]['online_count'][i][mask]\n",
    "            data[k]['online_sec'][i][mask] += delta * (values - data[k]['online_avg'][i][mask])\n",
    "            data[k]['online_min'][i][mask] = np.minimum(data[k]['online_min'][i][mask], values)\n",
    "            data[k]['online_max'][i][mask] = np.maximum(data[k]['online_max'][i][mask], values)\n",
    "\n",
    "            values = np.array(row['activation_similarity'])[j:j + l]\n",
    "            mask = np.where(np.array(np.invert(np.isnan(values)), dtype=int))[0]\n",
    "            values = values[mask]\n",
    "            delta = values - data[k]['as_avg'][i][mask]\n",
    "            data[k]['as_count'][i][mask] += 1\n",
    "            data[k]['as_avg'][i][mask] += delta / data[k]['as_count'][i][mask]\n",
    "            data[k]['as_sec'][i][mask] += delta * (values - data[k]['as_avg'][i][mask])\n",
    "            data[k]['as_min'][i][mask] = np.minimum(data[k]['as_min'][i][mask], values)\n",
    "            data[k]['as_max'][i][mask] = np.maximum(data[k]['as_max'][i][mask], values)\n",
    "\n",
    "            values = np.array(row['pairwise_interference'])[j:j + l]\n",
    "            mask = np.where(np.array(np.invert(np.isnan(values)), dtype=int))[0]\n",
    "            values = values[mask]\n",
    "            delta = values - data[k]['pi_avg'][i][mask]\n",
    "            data[k]['pi_count'][i][mask] += 1\n",
    "            data[k]['pi_avg'][i][mask] += delta / data[k]['pi_count'][i][mask]\n",
    "            data[k]['pi_sec'][i][mask] += delta * (values - data[k]['pi_avg'][i][mask])\n",
    "            data[k]['pi_min'][i][mask] = np.minimum(data[k]['pi_min'][i][mask], values)\n",
    "            data[k]['pi_max'][i][mask] = np.maximum(data[k]['pi_max'][i][mask], values)\n",
    "\n",
    "            j += l\n",
    "    data[k]['d1_sem'] = list()\n",
    "    data[k]['d2_sem'] = list()\n",
    "    data[k]['online_sem'] = list()\n",
    "    data[k]['as_sem'] = list()\n",
    "    data[k]['pi_sem'] = list()\n",
    "    for i in range(len(max_phase_lengths)):\n",
    "        data[k]['d1_sem'].append(np.nan_to_num(np.sqrt(data[k]['d1_sec'][i]) / data[k]['d1_count'][i]))\n",
    "        data[k]['d2_sem'].append(np.nan_to_num(np.sqrt(data[k]['d2_sec'][i]) / data[k]['d2_count'][i]))\n",
    "        data[k]['online_sem'].append(np.nan_to_num(np.sqrt(data[k]['online_sec'][i]) / data[k]['online_count'][i]))\n",
    "        data[k]['as_sem'].append(np.nan_to_num(np.sqrt(data[k]['as_sec'][i]) / data[k]['as_count'][i]))\n",
    "        data[k]['pi_sem'].append(np.nan_to_num(np.sqrt(data[k]['pi_sec'][i]) / data[k]['pi_count'][i]))\n",
    "    del data[k]['d1_sec']\n",
    "    del data[k]['d2_sec']\n",
    "    del data[k]['online_sec']\n",
    "    del data[k]['as_sec']\n",
    "    del data[k]['pi_sec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = {k: v for k, v in data.items() if (len(k) == 1) or ((k[0] == 'momentum') and (k[1] == 0.9)) or ((k[0] == 'rms') and (k[1] == 0.999))}\n",
    "threshold = 125\n",
    "fig, axarr = plt.subplots(4, 1, figsize=(5.5, 5.5), dpi=300, sharex=True)\n",
    "colors = sns.color_palette('colorblind', len(plot_data.keys()))\n",
    "xmax = 0\n",
    "for j in range(len(axarr)):\n",
    "    ax = axarr[j]\n",
    "    for i, (k, v) in enumerate(sorted(plot_data.items(), key=lambda x: x[0])):\n",
    "        other_phase = (j + 1) % 2 + 1\n",
    "        x = np.where(v['d{}_count'.format(other_phase)][j] >= threshold)[0]\n",
    "        xmax = max(xmax, max(x))\n",
    "        y = v['d{}_avg'.format(other_phase)][j][x]\n",
    "        yerr = v['d{}_sem'.format(other_phase)][j][x]\n",
    "        ax.fill_between(x, y - yerr, y + yerr, color=colors[i], alpha=0.1)\n",
    "        ax.plot(x, y, color=colors[i], linestyle='--', linewidth=1)\n",
    "\n",
    "        label = optimizer_nice_names[k[0]] if j == 0 else None\n",
    "        x = np.where(v['online_count'][j] >= threshold)[0]\n",
    "        xmax = max(xmax, max(x))\n",
    "        y = v['online_avg'][j][x]\n",
    "        yerr = v['online_sem'][j][x]\n",
    "        ax.fill_between(x, y - yerr, y + yerr, color=colors[i], alpha=0.1)\n",
    "        ax.plot(x, y, label=label, color=colors[i], linestyle='-', linewidth=1)\n",
    "\n",
    "for j in range(len(axarr)):\n",
    "    ax = axarr[j]\n",
    "    ax.set_ylim(-0.05, 1.05)\n",
    "    ax.set_yticks([0.0, 0.5, 1.0])\n",
    "    ax.set_xlim((0, xmax * 1.05))\n",
    "    ax.set_ylabel('Phase {}'.format(j + 1), labelpad=Y_LABEL_PAD)\n",
    "axarr[0].set_title('Accuracy')\n",
    "axarr[-1].set_xticks([0, 50, 100, 150, 200, 250])\n",
    "axarr[-1].set_xlim(0, 250)\n",
    "axarr[-1].set_xlabel('Steps', labelpad=X_LABEL_PAD)\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(hspace=0.15, right=0.775)\n",
    "pos = axarr[0].get_position()\n",
    "fig.legend(bbox_to_anchor=(1, pos.y0 + (pos.y1 - pos.y0) / 2), loc='center right')\n",
    "fig.savefig('experiment_2_mnist_accuracies.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_lengths = [{optimizer: list() for optimizer in rdf['optimizer'].unique()} for _ in range(4)]\n",
    "for _, row in rdf.iterrows():\n",
    "    if (row['optimizer'] == 'momentum') and (row['momentum'] != 0.9):\n",
    "        continue\n",
    "    if (row['optimizer'] == 'rms') and (row['rho'] != 0.999):\n",
    "        continue\n",
    "    for i in range(4):\n",
    "        phase_lengths[i][row['optimizer']].append(row['phase_length'][i])\n",
    "\n",
    "text = ''\n",
    "text += '|-----------|------------------|------------------|------------------|------------------|\\n'\n",
    "text += '| Optimizer | Steps in Phase 1 | Steps in Phase 2 | Steps in Phase 3 | Steps in Phase 4 |\\n'\n",
    "text += '|-----------|------------------|------------------|------------------|------------------|\\n'\n",
    "for optimizer in sorted(list(phase_lengths[0].keys())):\n",
    "    text += '| {0:>9} |   {1:>6.2f}+-{2:<4.2f}   |   {3:>6.2f}+-{4:<4.2f}   |   {5:>6.2f}+-{6:<4.2f}   |   {7:>6.2f}+-{8:<4.2f}   |\\n'.format(\n",
    "        optimizer_nice_names[optimizer],\n",
    "        np.mean(phase_lengths[0][optimizer]), np.std(phase_lengths[0][optimizer]) / np.sqrt(len(phase_lengths[0][optimizer])),\n",
    "        np.mean(phase_lengths[1][optimizer]), np.std(phase_lengths[1][optimizer]) / np.sqrt(len(phase_lengths[1][optimizer])),\n",
    "        np.mean(phase_lengths[2][optimizer]), np.std(phase_lengths[2][optimizer]) / np.sqrt(len(phase_lengths[2][optimizer])),\n",
    "        np.mean(phase_lengths[3][optimizer]), np.std(phase_lengths[3][optimizer]) / np.sqrt(len(phase_lengths[3][optimizer])))\n",
    "text += '|-----------|------------------|------------------|------------------|------------------|'\n",
    "with open('experiment_2_mnist_speed.txt', 'w') as outfile:\n",
    "    print(text, file=outfile)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = {name: [[list() for j in range(2)] for i in range(4)] for name in list(set(rdf['optimizer'].unique()) - {'constant'})}\n",
    "for _, row in rdf.iterrows():\n",
    "    if row['optimizer'] == 'constant':\n",
    "        continue\n",
    "    if (row['optimizer'] == 'momentum') and (row['momentum'] != 0.9):\n",
    "        continue\n",
    "    if (row['optimizer'] == 'rms') and (row['rho'] != 0.999):\n",
    "        continue\n",
    "    for i in range(4):\n",
    "        for j in range(2):\n",
    "            accuracies[row['optimizer']][i][j].append(row['accuracies'][sum(row['phase_length'][:i + 1]) - 1][j])\n",
    "\n",
    "text = ''\n",
    "text += '|-----------|-------|-------------------|-------------------|\\n'\n",
    "text += '| Optimizer | Phase | Accuracy on 1 + 2 | Accuracy on 3 + 4 |\\n'\n",
    "text += '|-----------|-------|-------------------|-------------------|\\n'\n",
    "for optimizer in sorted(list(accuracies.keys())):\n",
    "    for phase in range(4):\n",
    "        if (optimizer != 'adam') and (phase == 0):\n",
    "            text += '|-----------|-------|-------------------|-------------------|\\n'\n",
    "        text += '| {0:>9} |   {1}   |  {2:>6.4f}+-{3:<6.4f}   |  {4:>6.4f}+-{5:<6.4f}   |\\n'.format(\n",
    "            optimizer_nice_names[optimizer] if phase == 1 else '',\n",
    "            phase,\n",
    "            np.mean(accuracies[optimizer][phase][0]), np.std(accuracies[optimizer][phase][0]) / np.sqrt(len(accuracies[optimizer][phase][0])),\n",
    "            np.mean(accuracies[optimizer][phase][1]), np.std(accuracies[optimizer][phase][1]) / np.sqrt(len(accuracies[optimizer][phase][1])))\n",
    "text += '|-----------|-------|-------------------|-------------------|\\n'\n",
    "with open('experiment_2_mnist_retention.txt', 'w') as outfile:\n",
    "    print(text, file=outfile)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_lengths = [{optimizer: list() for optimizer in rdf['optimizer'].unique()} for _ in range(4)]\n",
    "for _, row in rdf.iterrows():\n",
    "    if (row['optimizer'] == 'momentum') and (row['momentum'] != 0.9):\n",
    "        continue\n",
    "    if (row['optimizer'] == 'rms') and (row['rho'] != 0.999):\n",
    "        continue\n",
    "    for i in range(4):\n",
    "        phase_lengths[i][row['optimizer']].append(row['phase_length'][i])\n",
    "boxplot_data = {'optimizer': [], 'phase': [], 'phase_length': []}\n",
    "for optimizer in sorted(list(phase_lengths[2].keys())):\n",
    "    for i in range(len(phase_lengths[0][optimizer])):\n",
    "        first_phase_length = phase_lengths[0][optimizer][i]\n",
    "        third_phase_length = phase_lengths[2][optimizer][i]\n",
    "        boxplot_data['optimizer'].append(optimizer_nice_names[optimizer])\n",
    "        boxplot_data['phase'].append('Phase 1')\n",
    "        boxplot_data['phase_length'].append(first_phase_length)\n",
    "        boxplot_data['optimizer'].append(optimizer_nice_names[optimizer])\n",
    "        boxplot_data['phase'].append('Phase 3')\n",
    "        boxplot_data['phase_length'].append(third_phase_length)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3.5, 2.5), dpi=300)\n",
    "ax.set_xlabel('Phase Length', labelpad=X_LABEL_PAD)\n",
    "sns.violinplot(x='phase_length', y='optimizer', hue='phase', data=boxplot_data, cut=0, split=True, inner=None, ax=ax, legend=None)\n",
    "ax.set_xlim(0, 400)\n",
    "ax.set_xticks([0, 100, 200, 300, 400])\n",
    "sns.despine(offset=10, trim=True)\n",
    "fig.tight_layout()\n",
    "pos = ax.get_position()\n",
    "lgd = plt.legend(bbox_to_anchor=(1, pos.y1), loc='upper left')\n",
    "fig.savefig('experiment_2_mnist_relearning.pdf', bbox_extra_artists=(lgd,), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = {optimizer: list() for optimizer in rdf['optimizer'].unique()}\n",
    "for _, row in rdf.iterrows():\n",
    "    if (row['optimizer'] == 'momentum') and (row['momentum'] != 0.9):\n",
    "        continue\n",
    "    if (row['optimizer'] == 'rms') and (row['rho'] != 0.999):\n",
    "        continue\n",
    "    ratios[row['optimizer']].append(row['phase_length'][0] / row['phase_length'][2])\n",
    "\n",
    "text = ''\n",
    "text += '|-----------|------------|\\n'\n",
    "text += '| Optimizer | Relearning |\\n'\n",
    "text += '|---------- |------------|\\n'\n",
    "for optimizer in sorted(list(ratios.keys())):\n",
    "    text += '| {0:>9} | {1:>4.2f}+-{2:<4.2f} |\\n'.format(\n",
    "        optimizer_nice_names[optimizer],\n",
    "        np.mean(ratios[optimizer]),\n",
    "        np.std(ratios[optimizer]) / np.sqrt(len(ratios[optimizer])))\n",
    "text += '|---------- |------------|\\n'\n",
    "with open('experiment_2_mnist_relearning.txt', 'w') as outfile:\n",
    "    print(text, file=outfile)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = {k: v for k, v in data.items() if (len(k) == 1) or ((k[0] == 'momentum') and (k[1] == 0.9)) or ((k[0] == 'rms') and (k[1] == 0.999))}\n",
    "threshold = 125\n",
    "fig, axmat = plt.subplots(2, 4, sharex=True, dpi=300, figsize=(6, 3.5))\n",
    "colors = sns.color_palette('colorblind', len(data.keys()))\n",
    "xmax = 0\n",
    "for j in range(4):\n",
    "    for i, (k, v) in enumerate(sorted(plot_data.items(), key=lambda x: x[0])):\n",
    "        x = np.where(v['as_count'][j] >= threshold)[0]\n",
    "        xmax = max(xmax, max(x))\n",
    "        y = v['as_avg'][j][x]\n",
    "        yerr = v['as_sem'][j][x]\n",
    "        label = optimizer_nice_names[k[0]] if j == 0 else None\n",
    "        axmat[0, j].plot(\n",
    "            x,\n",
    "            y,\n",
    "            label=label,\n",
    "            linewidth=1,\n",
    "            color=colors[i])\n",
    "        axmat[0, j].fill_between(\n",
    "            x,\n",
    "            y - yerr,\n",
    "            y + yerr,\n",
    "            color=colors[i],\n",
    "            alpha=0.3)\n",
    "\n",
    "        x = np.where(v['pi_count'][j] >= threshold)[0]\n",
    "        xmax = max(xmax, max(x))\n",
    "        y = - v['pi_avg'][j][x]\n",
    "        yerr = v['pi_sem'][j][x]\n",
    "        axmat[1, j].plot(\n",
    "            x,\n",
    "            y,\n",
    "            linewidth=1,\n",
    "            color=colors[i])\n",
    "        axmat[1, j].fill_between(\n",
    "            x,\n",
    "            y - yerr,\n",
    "            y + yerr,\n",
    "            color=colors[i],\n",
    "            alpha=0.3)\n",
    "\n",
    "axmat[0, 0].set_ylabel('Activation\\nSimilarity', labelpad=Y_LABEL_PAD)\n",
    "axmat[1, 0].set_ylabel('Pairwise\\nInterference', labelpad=Y_LABEL_PAD)\n",
    "for i in range(4):\n",
    "    axmat[0, i].set_title('Phase {}'.format(i + 1))\n",
    "    axmat[1, i].set_xticks([0, 80, 160])\n",
    "    axmat[1, i].set_xlabel('Steps', labelpad=X_LABEL_PAD)\n",
    "    axmat[0, i].set_ylim(- 25, 250)\n",
    "    axmat[0, i].set_yticks([0, 100, 200])\n",
    "    axmat[1, i].set_ylim(- 0.175, 0.025)\n",
    "    axmat[1, i].set_yticks([-0.15, -0.1, -0.05, 0.0])\n",
    "    for j in range(2):\n",
    "        axmat[j, i].set_xlim(0, xmax * 1.05)\n",
    "        if i != 0:\n",
    "            axmat[j, i].tick_params(axis='y', which='both', left=False)\n",
    "            axmat[j, i].set_yticklabels([])\n",
    "fig.align_ylabels(axmat[:, 0])\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(hspace=0.0, wspace=0.0, right=0.775)\n",
    "pos = axmat[0, 0].get_position()\n",
    "fig.legend(bbox_to_anchor=(0.9825, pos.y0 + (pos.y1 - pos.y0) / 2), loc='center right', frameon=False)\n",
    "fig.savefig('experiment_2_mnist_additional_interference.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = sorted(list(rdf['optimizer'].unique()))\n",
    "retention = {optimizer: list() for optimizer in optimizers}\n",
    "relearning = copy.deepcopy(retention)\n",
    "for _, row in rdf.iterrows():\n",
    "    optimizer = row['optimizer']\n",
    "    if (optimizer == 'momentum') and (row['momentum'] != 0.9):\n",
    "        continue\n",
    "    if (optimizer == 'rms') and (row['rho'] != 0.999):\n",
    "        continue\n",
    "    retention[optimizer].append(row['accuracies'][sum(row['phase_length'][:2]) - 1][0])\n",
    "    relearning[optimizer].append(row['phase_length'][0] / row['phase_length'][2])\n",
    "\n",
    "labels = list()\n",
    "retention_y = list()\n",
    "retention_yerr = list()\n",
    "relearning_y = list()\n",
    "relearning_yerr = list()\n",
    "for optimizer in optimizers:\n",
    "    labels.append(optimizer_nice_names[optimizer])\n",
    "    retention_y.append(np.mean(retention[optimizer]))\n",
    "    retention_yerr.append(np.std(retention[optimizer]) / np.sqrt(len(retention[optimizer])))\n",
    "    relearning_y.append(np.mean(relearning[optimizer]))\n",
    "    relearning_yerr.append(np.std(relearning[optimizer]) / np.sqrt(len(relearning[optimizer])))\n",
    "x = np.arange(len(labels))\n",
    "\n",
    "fig, ax1 = plt.subplots(1, 1, dpi=300, figsize=(4, 2))\n",
    "ax2 = ax1.twinx()\n",
    "colors = sns.color_palette('colorblind', 2)\n",
    "width = 0.35\n",
    "ax1.bar(x - width / 2,\n",
    "        retention_y,\n",
    "        width,\n",
    "        yerr=retention_yerr,\n",
    "        label='Retention',\n",
    "        color=colors[0])\n",
    "ax2.bar(x + width / 2,\n",
    "        relearning_y,\n",
    "        width,\n",
    "        yerr=relearning_yerr,\n",
    "        label='Relearning',\n",
    "        color=colors[1])\n",
    "\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(labels)\n",
    "ax1.set_yticks([0, 0.1, 0.2, 0.3])\n",
    "ax1.set_ylim(0, 0.3)\n",
    "ax1.set_ylabel('Retention (left/blue)', labelpad=10)\n",
    "ax2.set_yticks([0, 1, 2, 3, 4])\n",
    "ax2.set_ylim(0, 4)\n",
    "ax2.set_ylabel('Relearning (right/yellow)', labelpad=10)\n",
    "fig.tight_layout()\n",
    "fig.savefig('experiment_2_mnist_retention_and_relearning.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = {optimizer: dict() for optimizer in ['momentum', 'rms']}\n",
    "retention = copy.deepcopy(accuracy)\n",
    "relearning = copy.deepcopy(accuracy)\n",
    "for _, row in rdf.iterrows():\n",
    "    optimizer = row['optimizer']\n",
    "    if optimizer == 'momentum':\n",
    "        gamma = row['momentum']\n",
    "    elif optimizer == 'rms':\n",
    "        gamma = row['rho']\n",
    "    else:\n",
    "        continue\n",
    "    if gamma not in accuracy[optimizer]:\n",
    "        assert(gamma not in retention[optimizer])\n",
    "        assert(gamma not in relearning[optimizer])\n",
    "        accuracy[optimizer][gamma] = list()\n",
    "        retention[optimizer][gamma] = list()\n",
    "        relearning[optimizer][gamma] = list()\n",
    "    accuracy[optimizer][gamma].append(row['accuracies'][sum(row['phase_length'][:1]) - 1][0])\n",
    "    retention[optimizer][gamma].append(row['accuracies'][sum(row['phase_length'][:2]) - 1][0])\n",
    "    relearning[optimizer][gamma].append(row['phase_length'][0] / row['phase_length'][2])\n",
    "\n",
    "text = ''\n",
    "text += '|-----------|--------|----------------|----------------|\\n'\n",
    "text += '| Optimizer | Gamma  |   Retention    |   Relearning   |\\n'\n",
    "text += '|-----------|--------|----------------|----------------|\\n'\n",
    "for optimizer in sorted(list(accuracy.keys())):\n",
    "    for i, gamma in enumerate(sorted(accuracy[optimizer].keys())):\n",
    "        text += '| {0:>9} | {1}  | {2:>6.4f}+-{3:<6.4f} | {4:>6.4f}+-{5:<6.4f} |\\n'.format(\n",
    "            optimizer_nice_names[optimizer] if i == 1 else '',\n",
    "            str(gamma).ljust(5),\n",
    "            np.mean(retention[optimizer][gamma]),\n",
    "            np.std(retention[optimizer][gamma]) / np.sqrt(len(retention[optimizer][gamma])),\n",
    "            np.mean(relearning[optimizer][gamma]),\n",
    "            np.std(relearning[optimizer][gamma]) / np.sqrt(len(relearning[optimizer][gamma])))\n",
    "    text += '|-----------|--------|----------------|----------------|\\n'\n",
    "with open('experiment_2_mnist_interference_momentum_and_rms.txt', 'w') as outfile:\n",
    "    print(text, file=outfile)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_data = {\n",
    "    r'$\\beta={}$'.format(k[1]) : v\n",
    "    for k, v in data.items()\n",
    "    if k[0] == 'momentum'}\n",
    "threshold = 125\n",
    "fig, axmat = plt.subplots(3, 4, sharex=True, dpi=300, figsize=(7, 4))\n",
    "colors = sns.color_palette('colorblind', len(data.keys()))\n",
    "xmax = 0\n",
    "for j in range(4):\n",
    "    for i, (k, v) in enumerate(sorted(plot_data.items(), key=lambda x: x[0])):\n",
    "        other_phase = (j + 1) % 2 + 1\n",
    "        x = np.where(v['d{}_count'.format(other_phase)][j] >= threshold)[0]\n",
    "        xmax = max(xmax, max(x))\n",
    "        y = v['d{}_avg'.format(other_phase)][j][x]\n",
    "        yerr = v['d{}_sem'.format(other_phase)][j][x]\n",
    "        label = k if j == 0 else None\n",
    "        axmat[0, j].plot(\n",
    "            x,\n",
    "            y,\n",
    "            linestyle='--',\n",
    "            linewidth=1,\n",
    "            color=colors[i])\n",
    "        axmat[0, j].fill_between(\n",
    "            x,\n",
    "            y - yerr,\n",
    "            y + yerr,\n",
    "            color=colors[i],\n",
    "            alpha=0.3)\n",
    "\n",
    "        x = np.where(v['online_count'][j] >= threshold)[0]\n",
    "        xmax = max(xmax, max(x))\n",
    "        y = v['online_avg'][j][x]\n",
    "        yerr = v['online_sem'][j][x]\n",
    "        axmat[0, j].plot(\n",
    "            x,\n",
    "            y,\n",
    "            label=label,\n",
    "            linewidth=1,\n",
    "            color=colors[i])\n",
    "        axmat[0, j].fill_between(\n",
    "            x,\n",
    "            y - yerr,\n",
    "            y + yerr,\n",
    "            color=colors[i],\n",
    "            alpha=0.3)\n",
    "\n",
    "        x = np.where(v['as_count'][j] >= threshold)[0]\n",
    "        xmax = max(xmax, max(x))\n",
    "        y = v['as_avg'][j][x]\n",
    "        yerr = v['as_sem'][j][x]\n",
    "        axmat[1, j].plot(\n",
    "            x,\n",
    "            y,\n",
    "            linewidth=1,\n",
    "            color=colors[i])\n",
    "        axmat[1, j].fill_between(\n",
    "            x,\n",
    "            y - yerr,\n",
    "            y + yerr,\n",
    "            color=colors[i],\n",
    "            alpha=0.3)\n",
    "\n",
    "        x = np.where(v['pi_count'][j] >= threshold)[0]\n",
    "        xmax = max(xmax, max(x))\n",
    "        y = - v['pi_avg'][j][x]\n",
    "        yerr = v['pi_sem'][j][x]\n",
    "        axmat[2, j].plot(\n",
    "            x,\n",
    "            y,\n",
    "            linewidth=1,\n",
    "            color=colors[i])\n",
    "        axmat[2, j].fill_between(\n",
    "            x,\n",
    "            y - yerr,\n",
    "            y + yerr,\n",
    "            color=colors[i],\n",
    "            alpha=0.3)\n",
    "\n",
    "axmat[0, 0].set_ylabel('Accuracy', labelpad=Y_LABEL_PAD)\n",
    "axmat[1, 0].set_ylabel('Activation\\nSimilarity', labelpad=Y_LABEL_PAD)\n",
    "axmat[2, 0].set_ylabel('Pairwise\\nInterference', labelpad=Y_LABEL_PAD)\n",
    "for i in range(4):\n",
    "    axmat[0, i].set_title('Phase {}'.format(i + 1))\n",
    "    axmat[0, i].set_ylim(-0.05, 1.05)\n",
    "    axmat[0, i].set_yticks([0.0, 0.5, 1.0])\n",
    "    axmat[1, i].set_ylim(- 25, 375)\n",
    "    axmat[1, i].set_yticks([0, 100, 200, 300])\n",
    "    axmat[2, i].set_ylim(- 0.2, 0.025)\n",
    "    axmat[2, i].set_yticks([- 0.15, - 0.1, - 0.05, 0.0])\n",
    "    axmat[2, i].set_xticks([0, 400, 800])\n",
    "    axmat[2, i].set_xlabel('Steps', labelpad=X_LABEL_PAD)\n",
    "    for j in range(3):\n",
    "        axmat[j, i].set_xlim(0, xmax * 1.05)\n",
    "        if i != 0:\n",
    "            axmat[j, i].tick_params(axis='y', which='both', left=False)\n",
    "            axmat[j, i].set_yticklabels([])\n",
    "fig.align_ylabels(axmat[:, 0])\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(hspace=0.0, wspace=0.0, right=0.84)\n",
    "pos = axmat[0, 0].get_position()\n",
    "fig.legend(bbox_to_anchor=(1, pos.y0 + (pos.y1 - pos.y0) / 2), loc='center right')\n",
    "fig.savefig('experiment_2_mnist_additional_interference_momentum.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = {\n",
    "    r'$\\beta={}$'.format(k[1]) : v\n",
    "    for k, v in data.items()\n",
    "    if k[0] == 'rms'}\n",
    "threshold = 125\n",
    "fig, axmat = plt.subplots(3, 4, sharex=True, dpi=300, figsize=(7, 4))\n",
    "colors = sns.color_palette('colorblind', len(data.keys()))\n",
    "xmax = 0\n",
    "for j in range(4):\n",
    "    for i, (k, v) in enumerate(sorted(plot_data.items(), key=lambda x: x[0])):\n",
    "        other_phase = (j + 1) % 2 + 1\n",
    "        x = np.where(v['d{}_count'.format(other_phase)][j] >= threshold)[0]\n",
    "        xmax = max(xmax, max(x))\n",
    "        y = v['d{}_avg'.format(other_phase)][j][x]\n",
    "        yerr = v['d{}_sem'.format(other_phase)][j][x]\n",
    "        label = k if j == 0 else None\n",
    "        axmat[0, j].plot(\n",
    "            x,\n",
    "            y,\n",
    "            linestyle='--',\n",
    "            linewidth=1,\n",
    "            color=colors[i])\n",
    "        axmat[0, j].fill_between(\n",
    "            x,\n",
    "            y - yerr,\n",
    "            y + yerr,\n",
    "            color=colors[i],\n",
    "            alpha=0.3)\n",
    "\n",
    "        x = np.where(v['online_count'][j] >= threshold)[0]\n",
    "        xmax = max(xmax, max(x))\n",
    "        y = v['online_avg'][j][x]\n",
    "        yerr = v['online_sem'][j][x]\n",
    "        axmat[0, j].plot(\n",
    "            x,\n",
    "            y,\n",
    "            label=label,\n",
    "            linewidth=1,\n",
    "            color=colors[i])\n",
    "        axmat[0, j].fill_between(\n",
    "            x,\n",
    "            y - yerr,\n",
    "            y + yerr,\n",
    "            color=colors[i],\n",
    "            alpha=0.3)\n",
    "\n",
    "        x = np.where(v['as_count'][j] >= threshold)[0]\n",
    "        xmax = max(xmax, max(x))\n",
    "        y = v['as_avg'][j][x]\n",
    "        yerr = v['as_sem'][j][x]\n",
    "        axmat[1, j].plot(\n",
    "            x,\n",
    "            y,\n",
    "            linewidth=1,\n",
    "            color=colors[i])\n",
    "        axmat[1, j].fill_between(\n",
    "            x,\n",
    "            y - yerr,\n",
    "            y + yerr,\n",
    "            color=colors[i],\n",
    "            alpha=0.3)\n",
    "\n",
    "        x = np.where(v['pi_count'][j] >= threshold)[0]\n",
    "        xmax = max(xmax, max(x))\n",
    "        y = - v['pi_avg'][j][x]\n",
    "        yerr = v['pi_sem'][j][x]\n",
    "        axmat[2, j].plot(\n",
    "            x,\n",
    "            y,\n",
    "            linewidth=1,\n",
    "            color=colors[i])\n",
    "        axmat[2, j].fill_between(\n",
    "            x,\n",
    "            y - yerr,\n",
    "            y + yerr,\n",
    "            color=colors[i],\n",
    "            alpha=0.3)\n",
    "\n",
    "axmat[0, 0].set_ylabel('Accuracy', labelpad=Y_LABEL_PAD)\n",
    "axmat[1, 0].set_ylabel('Activation\\nSimilarity', labelpad=Y_LABEL_PAD)\n",
    "axmat[2, 0].set_ylabel('Pairwise\\nInterference', labelpad=Y_LABEL_PAD)\n",
    "for i in range(4):\n",
    "    axmat[0, i].set_title('Phase {}'.format(i + 1))\n",
    "    axmat[0, i].set_ylim(-0.05, 1.05)\n",
    "    axmat[0, i].set_yticks([0.0, 0.5, 1.0])\n",
    "    axmat[1, i].set_ylim(- 25, 375)\n",
    "    axmat[1, i].set_yticks([0, 100, 200, 300])\n",
    "    axmat[2, i].set_ylim(- 0.2, 0.025)\n",
    "    axmat[2, i].set_yticks([-0.15, -0.1, -0.05, 0.0])\n",
    "    axmat[2, i].set_xticks([0, 50, 100])\n",
    "    axmat[2, i].set_xlabel('Steps', labelpad=X_LABEL_PAD)\n",
    "    for j in range(3):\n",
    "        axmat[j, i].set_xlim(0, xmax * 1.05)\n",
    "        if i != 0:\n",
    "            axmat[j, i].tick_params(axis='y', which='both', left=False)\n",
    "            axmat[j, i].set_yticklabels([])\n",
    "fig.align_ylabels(axmat[:, 0])\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(hspace=0.0, wspace=0.0, right=0.83)\n",
    "pos = axmat[0, 0].get_position()\n",
    "fig.legend(bbox_to_anchor=(1, pos.y0 + (pos.y1 - pos.y0) / 2), loc='center right')\n",
    "fig.savefig('experiment_2_mnist_additional_interference_rms.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=#top>Back to Top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2 Mountain Car<a name='experiment_2_mountain_car'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Phase<a name='experiment_2_mountain_car_validation'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mc_tools.load_data(['experiment_2_mountain_car_validation.json'])\n",
    "summary = mc_tools.get_summary(data)\n",
    "best = mc_tools.get_best(data, ['optimizer', 'momentum', 'rho'], 'auc', summary=summary)\n",
    "best.head(n=len(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr_comparison = dict()\n",
    "for optimizer in set(summary['optimizer'].unique()) - {'constant'}:\n",
    "    lr_comparison[optimizer] = summary[summary['optimizer'] == optimizer].sort_values('lr')\n",
    "lr_comparison['momentum'] = lr_comparison['momentum'][lr_comparison['momentum']['momentum'] == 0.9]\n",
    "lr_comparison['rms'] = lr_comparison['rms'][lr_comparison['rms']['rho'] == 0.999]\n",
    "\n",
    "colors = sns.color_palette(n_colors=len(lr_comparison.keys()))\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, sharex=True, dpi=300, figsize=(4.5, 5.5))\n",
    "sort_key = lambda x: x[0]\n",
    "for i, (optimizer, value) in enumerate(sorted(lr_comparison.items(), key=sort_key)):\n",
    "    y1 = value['mean_accuracy_mean'].to_numpy()\n",
    "    y1err = value['mean_accuracy_stderr'].to_numpy()\n",
    "    y1[np.isnan(y1)] = 95  # plot out of axis values to show divergence\n",
    "    x = value['lr']\n",
    "    ax1.plot(\n",
    "        x,\n",
    "        y1,\n",
    "        '-o',\n",
    "        label=optimizer_nice_names[optimizer],\n",
    "        markersize=2,\n",
    "        linewidth=1,\n",
    "        color=colors[i])\n",
    "    ax1.fill_between(\n",
    "        x,\n",
    "        y1 - y1err,\n",
    "        y1 + y1err,\n",
    "        alpha=0.3,\n",
    "        color=colors[i])\n",
    "\n",
    "    value = value[value['final_accuracy_mean'].notnull()]\n",
    "    x = value['lr']\n",
    "    try:\n",
    "        y2 = value['mean_activation_similarity_mean']\n",
    "        y2err = value['mean_activation_similarity_stderr']\n",
    "        ax2.plot(\n",
    "            x,\n",
    "            y2,\n",
    "            '-o',\n",
    "            linewidth=1,\n",
    "            markersize=2,\n",
    "            color=colors[i])\n",
    "        ax2.fill_between(\n",
    "            x,\n",
    "            y2 - y2err,\n",
    "            y2 + y2err,\n",
    "            alpha=0.3,\n",
    "            color=colors[i])\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        y3 = value['mean_pairwise_interference_mean']\n",
    "        y3err = value['mean_pairwise_interference_stderr']\n",
    "        ax3.plot(\n",
    "            x,\n",
    "            y3,\n",
    "            '-o',\n",
    "            linewidth=1,\n",
    "            markersize=2,\n",
    "            color=colors[i])\n",
    "        ax3.fill_between(\n",
    "            x,\n",
    "            y3 - y3err,\n",
    "            y3 + y3err,\n",
    "            alpha=0.3,\n",
    "            color=colors[i])\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "ax1.set_xscale('log', basex=2)\n",
    "ax1.set_ylabel('$\\overline{\\mbox{RMSVE}}$', labelpad=Y_LABEL_PAD)\n",
    "ax1.set_ylim(20, 90)\n",
    "ax1.set_yticks([30, 60, 90])\n",
    "ax2.set_ylabel('$\\overline{\\mbox{Activation Similarity}}$', labelpad=Y_LABEL_PAD)\n",
    "ax2.set_ylim(- 25, 425)\n",
    "ax2.set_yticks([0, 200, 400])\n",
    "ax3.set_ylabel('$\\overline{\\mbox{Pairwise Interference}}$', labelpad=Y_LABEL_PAD)\n",
    "ax3.set_ylim(- 425, 25)\n",
    "ax3.set_yticks([- 400, - 200, 0])\n",
    "ax3.set_xlim(2 ** (-18), 2 ** (-3))\n",
    "ax3.set_xticks([2 ** (-18), 2 ** (-13), 2 ** (-8), 2 ** (-3)])\n",
    "ax3.set_xlabel('Step-size', labelpad=X_LABEL_PAD)\n",
    "fig.align_ylabels((ax1, ax2, ax3))\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(hspace=0.0, right=0.725)\n",
    "pos = ax1.get_position()\n",
    "fig.legend(bbox_to_anchor=(1, pos.y0 + (pos.y1 - pos.y0) / 2), loc='center right')\n",
    "fig.savefig('experiment_2_mountain_car_step-size.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=#top>Back to Top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Phase<a name='experiment_2_mountain_car_testing'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mc_tools.load_data(['experiment_2_mountain_car_test.json'])\n",
    "summary = mc_tools.get_summary(data)\n",
    "summary.head(n=len(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rdf = summary[np.isnan(summary['momentum']) | (summary['momentum'] == 0.9)]\n",
    "rdf = rdf[np.isnan(rdf['rho']) | (rdf['rho'] == 0.999)]\n",
    "\n",
    "colors = sns.color_palette(n_colors=len(rdf.keys()))\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, sharex=True, dpi=300, figsize=(4.5, 5.5))\n",
    "sort_key = lambda x: '~' if x == 'constant' else x\n",
    "for i, optimizer in enumerate(sorted(rdf['optimizer'].unique(), key=sort_key)):\n",
    "    value = rdf[rdf['optimizer'] == optimizer].iloc[0].to_dict()\n",
    "    y1 = value['accuracy_mean']\n",
    "    y1err = value['accuracy_stderr']\n",
    "    x = np.arange(len(y1)) + 1\n",
    "    ax1.plot(\n",
    "        x,\n",
    "        y1,\n",
    "        label=optimizer_nice_names[optimizer],\n",
    "        linewidth=1,\n",
    "        color=colors[i])\n",
    "    ax1.fill_between(\n",
    "        x,\n",
    "        y1 - y1err,\n",
    "        y1 + y1err,\n",
    "        alpha=0.3,\n",
    "        color=colors[i])\n",
    "\n",
    "    if optimizer == 'constant':\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        y2 = value['activation_similarity_mean']\n",
    "        y2err = value['activation_similarity_stderr']\n",
    "        ax2.plot(\n",
    "            x,\n",
    "            y2,\n",
    "            linewidth=1,\n",
    "            color=colors[i])\n",
    "        ax2.fill_between(\n",
    "            x,\n",
    "            y2 - y2err,\n",
    "            y2 + y2err,\n",
    "            alpha=0.3,\n",
    "            color=colors[i])\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        y3 = value['pairwise_interference_mean']\n",
    "        y3err = value['pairwise_interference_stderr']\n",
    "        ax3.plot(\n",
    "            x,\n",
    "            y3,\n",
    "            linewidth=1,\n",
    "            color=colors[i])\n",
    "        ax3.fill_between(\n",
    "            x,\n",
    "            y3 - y3err,\n",
    "            y3 + y3err,\n",
    "            alpha=0.3,\n",
    "            color=colors[i])\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "ax1.set_ylabel('RMSVE', labelpad=Y_LABEL_PAD)\n",
    "ax1.set_ylim(20, 90)\n",
    "ax1.set_yticks([30, 60, 90])\n",
    "ax2.set_ylabel('Activation Similarity', labelpad=Y_LABEL_PAD)\n",
    "ax2.set_ylim(- 10, 260)\n",
    "ax2.set_yticks([0, 100, 200])\n",
    "ax3.set_ylabel('Pairwise Interference', labelpad=Y_LABEL_PAD)\n",
    "ax3.set_ylim(- 1050, 250)\n",
    "ax3.set_yticks([- 1000, - 500, 0])\n",
    "ax3.set_xlim(0, 500)\n",
    "ax3.set_xlabel('Episode', labelpad=X_LABEL_PAD)\n",
    "fig.align_ylabels((ax1, ax2, ax3))\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(hspace=0.0, right=0.725)\n",
    "pos = ax1.get_position()\n",
    "fig.legend(bbox_to_anchor=(1, pos.y0 + (pos.y1 - pos.y0) / 2), loc='center right')\n",
    "fig.savefig('experiment_2_mountain_car_accuracies_and_interference.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = summary[np.isnan(summary['momentum']) | (summary['momentum'] == 0.9)]\n",
    "rdf = rdf[np.isnan(rdf['rho']) | (rdf['rho'] == 0.999)]\n",
    "sort_key = lambda x: '~' if x == 'constant' else x\n",
    "optimizers = sorted(rdf['optimizer'].unique(), key=sort_key)\n",
    "optimizers = [optimizer for optimizer in optimizers if optimizer != 'constant']\n",
    "\n",
    "text = ''\n",
    "text += '|---------------------------|-----------|---------------|--------------|\\n'\n",
    "text += '|          Metric           | Optimizer |  Mean Value   | Final Value  |\\n'\n",
    "text += '|---------------------------|-----------|---------------|--------------|\\n'\n",
    "for metric in ['activation_similarity', 'pairwise_interference']:\n",
    "    for i, optimizer in enumerate(optimizers):\n",
    "        mean_metric_mean = rdf[rdf['optimizer'] == optimizer].iloc[0].to_dict()['mean_{}_mean'.format(metric)]\n",
    "        mean_metric_stderr = rdf[rdf['optimizer'] == optimizer].iloc[0].to_dict()['mean_{}_stderr'.format(metric)]\n",
    "        final_metric_mean = rdf[rdf['optimizer'] == optimizer].iloc[0].to_dict()['final_{}_mean'.format(metric)]\n",
    "        final_metric_stderr = rdf[rdf['optimizer'] == optimizer].iloc[0].to_dict()['final_{}_stderr'.format(metric)]\n",
    "        text += '| {0:>25} | {1:<9} | {2:>7.2f}+-{3:<4.2f} | {4:>6.2f}+-{5:<4.2f} |\\n'.format(\n",
    "            metric.replace('_', ' ').title() if i == 1 else '',\n",
    "            optimizer_nice_names[optimizer],\n",
    "            mean_metric_mean,\n",
    "            mean_metric_stderr,\n",
    "            final_metric_mean,\n",
    "            final_metric_stderr)\n",
    "    text += '|---------------------------|-----------|---------------|--------------|\\n'\n",
    "with open('experiment_2_mountain_car_metrics.txt', 'w') as outfile:\n",
    "    print(text, file=outfile)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "colors = sns.color_palette(n_colors=4)\n",
    "fig, axmat = plt.subplots(3, 2, sharex=True, dpi=300, figsize=(5.5, 5.5))\n",
    "sort_key = lambda x: '~' if x == 'constant' else x\n",
    "for i, (optimizer, hyperparameter) in enumerate([('momentum', 'momentum'), ('rms', 'rho')]):\n",
    "    rdf = summary[summary['optimizer'] == optimizer]\n",
    "    for j, key in enumerate(['accuracy', 'activation_similarity', 'pairwise_interference']):\n",
    "        hyperparameter_values = sorted(rdf[hyperparameter].unique())\n",
    "        for k, hyperparameter_value in enumerate(hyperparameter_values):\n",
    "            value = rdf[rdf[hyperparameter] == hyperparameter_value].iloc[0].to_dict()\n",
    "            ax = axmat[j, i]\n",
    "            try:\n",
    "                y = value['{}_mean'.format(key)]\n",
    "                yerr = value['{}_stderr'.format(key)]\n",
    "                x = np.arange(len(y)) + 1\n",
    "                if (i == 1) and (j == 0):\n",
    "                    label = hyperparameter_value\n",
    "                else:\n",
    "                    label = None\n",
    "                ax.plot(\n",
    "                    x,\n",
    "                    y,\n",
    "                    label=label,\n",
    "                    linewidth=1,\n",
    "                    color=colors[k])\n",
    "                ax.fill_between(\n",
    "                    x,\n",
    "                    y - yerr,\n",
    "                    y + yerr,\n",
    "                    alpha=0.3,\n",
    "                    color=colors[k])\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "axmat[0, 0].set_title('Momentum')\n",
    "axmat[0, 1].set_title('RMSProp')\n",
    "axmat[0, 0].set_ylabel('RMSVE', labelpad=Y_LABEL_PAD)\n",
    "axmat[0, 0].set_ylim(20, 90)\n",
    "axmat[0, 0].set_yticks([30, 60, 90])\n",
    "axmat[0, 1].set_ylim(20, 90)\n",
    "axmat[0, 1].set_yticks([30, 60, 90])\n",
    "axmat[1, 0].set_ylabel('Activation Similarity', labelpad=Y_LABEL_PAD)\n",
    "axmat[1, 0].set_ylim(- 10, 260)\n",
    "axmat[1, 0].set_yticks([0, 100, 200])\n",
    "axmat[1, 1].set_ylim(- 10, 260)\n",
    "axmat[1, 1].set_yticks([0, 100, 200])\n",
    "axmat[2, 0].set_ylabel('Pairwise Interference', labelpad=Y_LABEL_PAD)\n",
    "axmat[2, 0].set_ylim(- 1050, 250)\n",
    "axmat[2, 0].set_yticks([- 1000, - 500, 0])\n",
    "axmat[2, 1].set_ylim(- 1050, 250)\n",
    "axmat[2, 1].set_yticks([- 1000, - 500, 0])\n",
    "for i in range(2):\n",
    "    axmat[2, i].set_xlim(0, 500)\n",
    "    axmat[2, i].set_xlabel('Episode', labelpad=X_LABEL_PAD)\n",
    "fig.align_ylabels(axmat[:, 0])\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(hspace=0.0, wspace=0.375, right=0.83)\n",
    "pos = axmat[0, 0].get_position()\n",
    "fig.legend(bbox_to_anchor=(1, pos.y0 + (pos.y1 - pos.y0) / 2), loc='center right')\n",
    "fig.savefig('experiment_2_mountain_car_momentum_and_rms.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=#top>Back to Top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2 Acrobot<a name='experiment_2_acrobot'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Phase<a name='experiment_2_acrobot_validation'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = ac_tools.load_data(['experiment_2_acrobot_validation.json'])\n",
    "summary = ac_tools.get_summary(data)\n",
    "best = ac_tools.get_best(data, ['optimizer', 'momentum', 'rho'], 'auc', summary=summary)\n",
    "best.head(n=len(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr_comparison = dict()\n",
    "for optimizer in set(summary['optimizer'].unique()) - {'constant'}:\n",
    "    lr_comparison[optimizer] = summary[summary['optimizer'] == optimizer].sort_values('lr')\n",
    "lr_comparison['momentum'] = lr_comparison['momentum'][lr_comparison['momentum']['momentum'] == 0.9]\n",
    "lr_comparison['rms'] = lr_comparison['rms'][lr_comparison['rms']['rho'] == 0.999]\n",
    "\n",
    "colors = sns.color_palette(n_colors=len(lr_comparison.keys()))\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, sharex=True, dpi=300, figsize=(4.5, 5.5))\n",
    "sort_key = lambda x: x[0]\n",
    "for i, (optimizer, value) in enumerate(sorted(lr_comparison.items(), key=sort_key)):\n",
    "    y1 = value['mean_accuracy_mean'].to_numpy()\n",
    "    y1err = value['mean_accuracy_stderr'].to_numpy()\n",
    "    y1[np.isnan(y1)] = 280  # plot out of axis values to show divergence\n",
    "    x = value['lr']\n",
    "    ax1.plot(\n",
    "        x,\n",
    "        y1,\n",
    "        '-o',\n",
    "        label=optimizer_nice_names[optimizer],\n",
    "        markersize=2,\n",
    "        linewidth=1,\n",
    "        color=colors[i])\n",
    "    ax1.fill_between(\n",
    "        x,\n",
    "        y1 - y1err,\n",
    "        y1 + y1err,\n",
    "        alpha=0.3,\n",
    "        color=colors[i])\n",
    "\n",
    "    value = value[value['final_accuracy_mean'].notnull()]\n",
    "    x = value['lr']\n",
    "    try:\n",
    "        y2 = value['mean_activation_similarity_mean']\n",
    "        y2err = value['mean_activation_similarity_stderr']\n",
    "        ax2.plot(\n",
    "            x,\n",
    "            y2,\n",
    "            '-o',\n",
    "            linewidth=1,\n",
    "            markersize=2,\n",
    "            color=colors[i])\n",
    "        ax2.fill_between(\n",
    "            x,\n",
    "            y2 - y2err,\n",
    "            y2 + y2err,\n",
    "            alpha=0.3,\n",
    "            color=colors[i])\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        y3 = value['mean_pairwise_interference_mean'].to_numpy()\n",
    "        y3err = value['mean_pairwise_interference_stderr'].to_numpy()\n",
    "        y3err[(y3 < - 2100) | (y3 > 100)] = 0  # stop standard error creeping in from out of axis values\n",
    "        ax3.plot(\n",
    "            x,\n",
    "            y3,\n",
    "            '-o',\n",
    "            linewidth=1,\n",
    "            markersize=2,\n",
    "            color=colors[i])\n",
    "        ax3.fill_between(\n",
    "            x,\n",
    "            y3 - y3err,\n",
    "            y3 + y3err,\n",
    "            alpha=0.3,\n",
    "            color=colors[i])\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "ax1.set_xscale('log', basex=2)\n",
    "ax1.set_ylabel('$\\overline{\\mbox{RMSVE}}$', labelpad=Y_LABEL_PAD)\n",
    "ax1.set_ylim(25, 275)\n",
    "ax1.set_yticks([50, 150, 250])\n",
    "ax2.set_ylabel('$\\overline{\\mbox{Activation Similarity}}$', labelpad=Y_LABEL_PAD)\n",
    "ax2.set_ylim(- 40, 240)\n",
    "ax2.set_yticks([0, 100, 200])\n",
    "ax3.set_ylabel('$\\overline{\\mbox{Pairwise Interference}}$', labelpad=Y_LABEL_PAD)\n",
    "ax3.set_ylim(- 2100, 100)\n",
    "ax3.set_yticks([- 2000, - 1000, 0])\n",
    "ax3.set_xlim(2 ** (-18), 2 ** (-3))\n",
    "ax3.set_xticks([2 ** (-18), 2 ** (-13), 2 ** (-8), 2 ** (-3)])\n",
    "ax3.set_xlabel('Step-size', labelpad=X_LABEL_PAD)\n",
    "fig.align_ylabels((ax1, ax2, ax3))\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(hspace=0.0, right=0.725)\n",
    "pos = ax1.get_position()\n",
    "fig.legend(bbox_to_anchor=(1, pos.y0 + (pos.y1 - pos.y0) / 2), loc='center right')\n",
    "fig.savefig('experiment_2_acrobot_step-size.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=#top>Back to Top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Phase<a name='experiment_2_acrobot_testing'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ac_tools.load_data(['experiment_2_acrobot_test.json'])\n",
    "summary = ac_tools.get_summary(data)\n",
    "summary.head(n=len(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rdf = summary[np.isnan(summary['momentum']) | (summary['momentum'] == 0.9)]\n",
    "rdf = rdf[np.isnan(rdf['rho']) | (rdf['rho'] == 0.999)]\n",
    "\n",
    "colors = sns.color_palette(n_colors=len(rdf.keys()))\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, sharex=True, dpi=300, figsize=(4.5, 5.5))\n",
    "sort_key = lambda x: '~' if x == 'constant' else x\n",
    "for i, optimizer in enumerate(sorted(rdf['optimizer'].unique(), key=sort_key)):\n",
    "    value = rdf[rdf['optimizer'] == optimizer].iloc[0].to_dict()\n",
    "    y1 = value['accuracy_mean']\n",
    "    y1err = value['accuracy_stderr']\n",
    "    x = np.arange(len(y1)) + 1\n",
    "    ax1.plot(\n",
    "        x,\n",
    "        y1,\n",
    "        label=optimizer_nice_names[optimizer],\n",
    "        linewidth=1,\n",
    "        color=colors[i])\n",
    "    ax1.fill_between(\n",
    "        x,\n",
    "        y1 - y1err,\n",
    "        y1 + y1err,\n",
    "        alpha=0.3,\n",
    "        color=colors[i])\n",
    "\n",
    "    if optimizer == 'constant':\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        y2 = value['activation_similarity_mean']\n",
    "        y2err = value['activation_similarity_stderr']\n",
    "        ax2.plot(\n",
    "            x,\n",
    "            y2,\n",
    "            linewidth=1,\n",
    "            color=colors[i])\n",
    "        ax2.fill_between(\n",
    "            x,\n",
    "            y2 - y2err,\n",
    "            y2 + y2err,\n",
    "            alpha=0.3,\n",
    "            color=colors[i])\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        y3 = value['pairwise_interference_mean']\n",
    "        y3err = value['pairwise_interference_stderr']\n",
    "        ax3.plot(\n",
    "            x,\n",
    "            y3,\n",
    "            linewidth=1,\n",
    "            color=colors[i])\n",
    "        ax3.fill_between(\n",
    "            x,\n",
    "            y3 - y3err,\n",
    "            y3 + y3err,\n",
    "            alpha=0.3,\n",
    "            color=colors[i])\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "ax1.set_ylabel('RMSVE', labelpad=Y_LABEL_PAD)\n",
    "ax1.set_ylim(20, 100)\n",
    "ax1.set_yticks([30, 60, 90])\n",
    "ax2.set_ylabel('Activation Similarity', labelpad=Y_LABEL_PAD)\n",
    "ax2.set_ylim(0, 300)\n",
    "ax2.set_yticks([50, 150, 250])\n",
    "ax3.set_ylabel('Pairwise Interference', labelpad=Y_LABEL_PAD)\n",
    "ax3.set_ylim(- 2100, 100)\n",
    "ax3.set_yticks([- 2000, - 1000, 0])\n",
    "ax3.set_xlim(0, 500)\n",
    "ax3.set_xlabel('Episode', labelpad=X_LABEL_PAD)\n",
    "fig.align_ylabels((ax1, ax2, ax3))\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(hspace=0.0, right=0.725)\n",
    "pos = ax1.get_position()\n",
    "fig.legend(bbox_to_anchor=(1, pos.y0 + (pos.y1 - pos.y0) / 2), loc='center right')\n",
    "fig.savefig('experiment_2_acrobot_accuracies_and_interference.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = summary[np.isnan(summary['momentum']) | (summary['momentum'] == 0.9)]\n",
    "rdf = rdf[np.isnan(rdf['rho']) | (rdf['rho'] == 0.999)]\n",
    "sort_key = lambda x: '~' if x == 'constant' else x\n",
    "optimizers = sorted(rdf['optimizer'].unique(), key=sort_key)\n",
    "optimizers = [optimizer for optimizer in optimizers if optimizer != 'constant']\n",
    "\n",
    "text = ''\n",
    "text += '|---------------------------|-----------|-----------------|----------------|\\n'\n",
    "text += '|          Metric           | Optimizer |   Mean Value    |  Final Value   |\\n'\n",
    "text += '|---------------------------|-----------|-----------------|----------------|\\n'\n",
    "for metric in ['activation_similarity', 'pairwise_interference']:\n",
    "    for i, optimizer in enumerate(optimizers):\n",
    "        mean_metric_mean = rdf[rdf['optimizer'] == optimizer].iloc[0].to_dict()['mean_{}_mean'.format(metric)]\n",
    "        mean_metric_stderr = rdf[rdf['optimizer'] == optimizer].iloc[0].to_dict()['mean_{}_stderr'.format(metric)]\n",
    "        final_metric_mean = rdf[rdf['optimizer'] == optimizer].iloc[0].to_dict()['final_{}_mean'.format(metric)]\n",
    "        final_metric_stderr = rdf[rdf['optimizer'] == optimizer].iloc[0].to_dict()['final_{}_stderr'.format(metric)]\n",
    "        text += '| {0:>25} | {1:<9} | {2:>8.2f}+-{3:<5.2f} | {4:>7.2f}+-{5:<5.2f} |\\n'.format(\n",
    "            metric.replace('_', ' ').title() if i == 1 else '',\n",
    "            optimizer_nice_names[optimizer],\n",
    "            mean_metric_mean,\n",
    "            mean_metric_stderr,\n",
    "            final_metric_mean,\n",
    "            final_metric_stderr)\n",
    "    text += '|---------------------------|-----------|-----------------|----------------|\\n'\n",
    "with open('experiment_2_acrobot_metrics.txt', 'w') as outfile:\n",
    "    print(text, file=outfile)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "colors = sns.color_palette(n_colors=4)\n",
    "fig, axmat = plt.subplots(3, 2, sharex=True, dpi=300, figsize=(5.5, 5.5))\n",
    "sort_key = lambda x: '~' if x == 'constant' else x\n",
    "for i, (optimizer, hyperparameter) in enumerate([('momentum', 'momentum'), ('rms', 'rho')]):\n",
    "    rdf = summary[summary['optimizer'] == optimizer]\n",
    "    for j, key in enumerate(['accuracy', 'activation_similarity', 'pairwise_interference']):\n",
    "        hyperparameter_values = sorted(rdf[hyperparameter].unique())\n",
    "        for k, hyperparameter_value in enumerate(hyperparameter_values):\n",
    "            value = rdf[rdf[hyperparameter] == hyperparameter_value].iloc[0].to_dict()\n",
    "            ax = axmat[j, i]\n",
    "            try:\n",
    "                y = value['{}_mean'.format(key)]\n",
    "                yerr = value['{}_stderr'.format(key)]\n",
    "                if key == 'accuracy':\n",
    "                    y[np.isnan(y)] = 105\n",
    "                x = np.arange(len(y)) + 1\n",
    "                if (i == 1) and (j == 0):\n",
    "                    label = hyperparameter_value\n",
    "                else:\n",
    "                    label = None\n",
    "                ax.plot(\n",
    "                    x,\n",
    "                    y,\n",
    "                    label=label,\n",
    "                    linewidth=1,\n",
    "                    color=colors[k])\n",
    "                ax.fill_between(\n",
    "                    x,\n",
    "                    y - yerr,\n",
    "                    y + yerr,\n",
    "                    alpha=0.3,\n",
    "                    color=colors[k])\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "axmat[0, 0].set_title('Momentum')\n",
    "axmat[0, 1].set_title('RMSProp')\n",
    "axmat[0, 0].set_ylabel('RMSVE', labelpad=Y_LABEL_PAD)\n",
    "axmat[0, 0].set_ylim(20, 100)\n",
    "axmat[0, 0].set_yticks([30, 60, 90])\n",
    "axmat[0, 1].set_ylim(20, 100)\n",
    "axmat[0, 1].set_yticks([30, 60, 90])\n",
    "axmat[1, 0].set_ylabel('Activation Similarity', labelpad=Y_LABEL_PAD)\n",
    "axmat[1, 0].set_ylim(0, 300)\n",
    "axmat[1, 0].set_yticks([50, 150, 250])\n",
    "axmat[1, 1].set_ylim(0, 300)\n",
    "axmat[1, 1].set_yticks([50, 150, 250])\n",
    "axmat[2, 0].set_ylabel('Pairwise Interference', labelpad=Y_LABEL_PAD)\n",
    "axmat[2, 0].set_ylim(- 2100, 100)\n",
    "axmat[2, 0].set_yticks([- 2000, - 1000, 0])\n",
    "axmat[2, 1].set_ylim(- 2100, 100)\n",
    "axmat[2, 1].set_yticks([- 2000, - 1000, 0])\n",
    "for i in range(2):\n",
    "    axmat[2, i].set_xlim(0, 500)\n",
    "    axmat[2, i].set_xlabel('Episode', labelpad=X_LABEL_PAD)\n",
    "fig.align_ylabels(axmat[: ,0])\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(hspace=0.0, wspace=0.375, right=0.83)\n",
    "pos = axmat[0, 0].get_position()\n",
    "fig.legend(bbox_to_anchor=(1, pos.y0 + (pos.y1 - pos.y0) / 2), loc='center right')\n",
    "fig.savefig('experiment_2_acrobot_momentum_and_rms.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=#top>Back to Top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presentation Exclusive<a name='presentation_exclusive'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1<a name='presentation_exclusive_experiment_1'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = mnist_tools.load_data(['experiment_1_mnist_test.json'])\n",
    "rdf = rdf[rdf['success']]\n",
    "E12 = ((1, 2), (3, 4), (1, 2), (3, 4))\n",
    "E34 = ((3, 4), (1, 2), (3, 4), (1, 2))\n",
    "E1234 = ((1, 2, 3, 4), (1, 2), (3, 4))\n",
    "ER = ((1, 2), (3, 4), (1, 2), (3, 4), (1, 2), (3, 4), (1, 2), (3, 4))\n",
    "\n",
    "# setup matplotlib\n",
    "sns.set_style('ticks')\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('ticks')\n",
    "sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_phase_lengths = list()\n",
    "for _, row in rdf.iterrows():\n",
    "    for i, l in enumerate(row['phase_length']):\n",
    "        if len(max_phase_lengths) == i:\n",
    "            max_phase_lengths.append(0)\n",
    "        max_phase_lengths[i] = max(max_phase_lengths[i], l)\n",
    "data = dict()\n",
    "for k in rdf['phases'].unique():\n",
    "    data[k] = dict()\n",
    "    for k2 in ['d1_count',\n",
    "               'd2_count']:\n",
    "        data[k][k2] = [np.zeros(i, dtype=int) for i in max_phase_lengths]\n",
    "    for k2 in ['d1_avg',\n",
    "               'd1_sec',\n",
    "               'd1_min',\n",
    "               'd1_max',\n",
    "               'd2_avg',\n",
    "               'd2_sec',\n",
    "               'd2_min',\n",
    "               'd2_max']:\n",
    "        data[k][k2] = [np.zeros(i, dtype=float) for i in max_phase_lengths]\n",
    "    data[k]['phase_lengths'] = [list() for i in max_phase_lengths]\n",
    "    for i in range(len(max_phase_lengths)):\n",
    "        data[k]['d1_min'][i] += 1\n",
    "        data[k]['d2_min'][i] += 1\n",
    "\n",
    "    kdf = rdf[rdf['phases'] == k]\n",
    "    for _, row in kdf.iterrows():\n",
    "        j = 0\n",
    "        for i, l in enumerate(row['phase_length']):\n",
    "            data[k]['phase_lengths'][i].append(l)\n",
    "\n",
    "            if k == E1234:\n",
    "                d1_index = 1\n",
    "                d2_index = 2\n",
    "            elif k == E12:\n",
    "                d1_index = 0\n",
    "                d2_index = 1\n",
    "            elif k == E34:\n",
    "                d1_index = 1\n",
    "                d2_index = 0\n",
    "            else:\n",
    "                assert k == ER\n",
    "                d1_index = 0\n",
    "                d2_index = 1\n",
    "\n",
    "            values = np.array(row['accuracies'])[j:j + l, d1_index]\n",
    "            mask = np.where(np.array(np.invert(np.isnan(values)), dtype=int))[0]\n",
    "            values = values[mask]\n",
    "            delta = values - data[k]['d1_avg'][i][mask]\n",
    "            data[k]['d1_count'][i][mask] += 1\n",
    "            data[k]['d1_avg'][i][mask] += delta / data[k]['d1_count'][i][mask]\n",
    "            data[k]['d1_sec'][i][mask] += delta * (values - data[k]['d1_avg'][i][mask])\n",
    "            data[k]['d1_min'][i][mask] = np.minimum(data[k]['d1_min'][i][mask], values)\n",
    "            data[k]['d1_max'][i][mask] = np.maximum(data[k]['d1_max'][i][mask], values)\n",
    "\n",
    "            values = np.array(row['accuracies'])[j:j + l, d2_index]\n",
    "            mask = np.where(np.array(np.invert(np.isnan(values)), dtype=int))[0]\n",
    "            values = values[mask]\n",
    "            delta = values - data[k]['d2_avg'][i][mask]\n",
    "            data[k]['d2_count'][i][mask] += 1\n",
    "            data[k]['d2_avg'][i][mask] += delta / data[k]['d2_count'][i][mask]\n",
    "            data[k]['d2_sec'][i][mask] += delta * (values - data[k]['d2_avg'][i][mask])\n",
    "            data[k]['d2_min'][i][mask] = np.minimum(data[k]['d2_min'][i][mask], values)\n",
    "            data[k]['d2_max'][i][mask] = np.maximum(data[k]['d2_max'][i][mask], values)\n",
    "\n",
    "            j += l\n",
    "    data[k]['d1_sem'] = list()\n",
    "    data[k]['d2_sem'] = list()\n",
    "    for i in range(len(max_phase_lengths)):\n",
    "        data[k]['d1_sem'].append(np.nan_to_num(np.sqrt(data[k]['d1_sec'][i]) / data[k]['d1_count'][i]))\n",
    "        data[k]['d2_sem'].append(np.nan_to_num(np.sqrt(data[k]['d2_sec'][i]) / data[k]['d2_count'][i]))\n",
    "    del data[k]['d1_sec']\n",
    "    del data[k]['d2_sec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 125\n",
    "fig, axarr = plt.subplots(3, 1, figsize=(3.6875, 4), dpi=300, sharex=True)\n",
    "colors = sns.color_palette('colorblind', len(data.keys()))\n",
    "xmax = 0\n",
    "\n",
    "# phase 1 plot\n",
    "ax = axarr[0]\n",
    "\n",
    "x = np.where(data[E12]['d1_count'][0] >= threshold)[0]\n",
    "xmax = max(xmax, max(x))\n",
    "y = data[E12]['d1_avg'][0][x]\n",
    "yerr = data[E12]['d1_sem'][0][x]\n",
    "ax.fill_between(x, y - yerr, y + yerr, color=colors[0], alpha=0.1)\n",
    "ax.plot(x, y, color=colors[0], label=r'$D_{(1 + 2)}$', linestyle='-', linewidth=1)\n",
    "\n",
    "x = np.where(data[E12]['d2_count'][0] >= threshold)[0]\n",
    "xmax = max(xmax, max(x))\n",
    "y = data[E12]['d2_avg'][0][x]\n",
    "yerr = data[E12]['d2_sem'][0][x]\n",
    "ax.fill_between(x, y - yerr, y + yerr, color=colors[0], alpha=0.1)\n",
    "ax.plot(x, y, color=colors[0], label=r'$D_{(3 + 4)}$', linestyle='--', linewidth=1)\n",
    "\n",
    "# phase 2 plot\n",
    "ax = axarr[1]\n",
    "\n",
    "x = np.where(data[E12]['d1_count'][1] >= threshold)[0]\n",
    "xmax = max(xmax, max(x))\n",
    "y = data[E12]['d1_avg'][1][x]\n",
    "yerr = data[E12]['d1_sem'][1][x]\n",
    "ax.fill_between(x, y - yerr, y + yerr, color=colors[0], alpha=0.1)\n",
    "ax.plot(x, y, color=colors[0], linestyle='-', linewidth=1)\n",
    "\n",
    "x = np.where(data[E12]['d2_count'][1] >= threshold)[0]\n",
    "xmax = max(xmax, max(x))\n",
    "y = data[E12]['d2_avg'][1][x]\n",
    "yerr = data[E12]['d2_sem'][1][x]\n",
    "ax.fill_between(x, y - yerr, y + yerr, color=colors[0], alpha=0.1)\n",
    "ax.plot(x, y, color=colors[0], linestyle='--', linewidth=1)\n",
    "\n",
    "# phase 3 plot\n",
    "ax = axarr[2]\n",
    "\n",
    "x = np.where(data[E12]['d1_count'][2] >= threshold)[0]\n",
    "xmax = max(xmax, max(x))\n",
    "y = data[E12]['d1_avg'][2][x]\n",
    "yerr = data[E12]['d1_sem'][2][x]\n",
    "ax.fill_between(x, y - yerr, y + yerr, color=colors[0], alpha=0.1)\n",
    "ax.plot(x, y, color=colors[0], linestyle='-', linewidth=1)\n",
    "\n",
    "x = np.where(data[E12]['d2_count'][2] >= threshold)[0]\n",
    "xmax = max(xmax, max(x))\n",
    "y = data[E12]['d2_avg'][2][x]\n",
    "yerr = data[E12]['d2_sem'][2][x]\n",
    "ax.fill_between(x, y - yerr, y + yerr, color=colors[0], alpha=0.1)\n",
    "ax.plot(x, y, color=colors[0], linestyle='--', linewidth=1)\n",
    "\n",
    "# clean up plot\n",
    "for j in range(len(axarr)):\n",
    "    ax = axarr[j]\n",
    "    ax.set_ylim(-0.1, 1.1)\n",
    "    ax.set_yticks([0.0, 0.5, 1.0])\n",
    "    ax.set_xlim(0, 200)\n",
    "    ax.set_ylabel('Phase {}'.format(j + 1), labelpad=10)\n",
    "axarr[2].set_xlabel('Steps', labelpad=10)\n",
    "axarr[0].set_title('Accuracy')\n",
    "lgd = axarr[0].legend(frameon=False, loc=(1.025, 0.225))\n",
    "fig.savefig('experiment_1_accuracies_single.pdf', bbox_extra_artists=(lgd,), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=#top>Back to Top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2 Mountain Car and Acrobot<a name='presentation_exclusive_experiment_2_mountain_car_and_acrobot'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_data = mc_tools.load_data(['experiment_2_mountain_car_test.json'])\n",
    "mc_summary = mc_tools.get_summary(mc_data)\n",
    "mc_summary.head(n=len(mc_summary))\n",
    "\n",
    "ac_data = ac_tools.load_data(['experiment_2_acrobot_test.json'])\n",
    "ac_summary = ac_tools.get_summary(ac_data)\n",
    "ac_summary.head(n=len(ac_summary))\n",
    "\n",
    "# setup matplotlib\n",
    "sns.set_style('ticks')\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('ticks')\n",
    "sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = sns.color_palette(n_colors=len(mc_summary['optimizer'].unique()) - 1)\n",
    "fig, axmat = plt.subplots(2, 2, sharex=True, dpi=300, figsize=(6, 4.5))\n",
    "sort_key = lambda x: '~' if x == 'constant' else x\n",
    "for i, (setting, summary) in enumerate([('Mountain Car', mc_summary), ('Acrobot', ac_summary)]):\n",
    "    rdf = summary[np.isnan(summary['momentum']) | (summary['momentum'] == 0.9)]\n",
    "    rdf = rdf[np.isnan(rdf['rho']) | (rdf['rho'] == 0.999)]\n",
    "    rdf = rdf[rdf['optimizer'] != 'constant']\n",
    "    for j, optimizer in enumerate(sorted(rdf['optimizer'].unique(), key=sort_key)):\n",
    "        value = rdf[rdf['optimizer'] == optimizer].iloc[0].to_dict()\n",
    "        try:\n",
    "            y2 = value['activation_similarity_mean']\n",
    "            y2err = value['activation_similarity_stderr']\n",
    "            x = np.arange(len(y2)) + 1\n",
    "            axmat[0, i].plot(\n",
    "                x,\n",
    "                y2,\n",
    "                label=optimizer_nice_names[optimizer] if i == 0 else None,\n",
    "                linewidth=1,\n",
    "                color=colors[j])\n",
    "            axmat[0, i].fill_between(\n",
    "                x,\n",
    "                y2 - y2err,\n",
    "                y2 + y2err,\n",
    "                alpha=0.3,\n",
    "                color=colors[j])\n",
    "        except KeyError:\n",
    "            pass\n",
    "        try:\n",
    "            y3 = value['pairwise_interference_mean']\n",
    "            y3err = value['pairwise_interference_stderr']\n",
    "            x = np.arange(len(y3)) + 1\n",
    "            axmat[1, i].plot(\n",
    "                x,\n",
    "                y3,\n",
    "                linewidth=1,\n",
    "                color=colors[j])\n",
    "            axmat[1, i].fill_between(\n",
    "                x,\n",
    "                y3 - y3err,\n",
    "                y3 + y3err,\n",
    "                alpha=0.3,\n",
    "                color=colors[j])\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "axmat[0, 0].set_ylabel('Activation Similarity', labelpad=10)\n",
    "axmat[1, 0].set_ylabel('Pairwise Interference', labelpad=10)\n",
    "axmat[0, 0].set_ylim(- 10, 260)\n",
    "axmat[0, 0].set_yticks([0, 100, 200])\n",
    "axmat[1, 0].set_ylim(- 1050, 250)\n",
    "axmat[1, 0].set_yticks([- 1000, - 500, 0])\n",
    "axmat[0, 1].set_ylim(- 5, 105)\n",
    "axmat[0, 1].set_yticks([0, 50, 100])\n",
    "axmat[1, 1].set_ylim(- 2100, 100)\n",
    "axmat[1, 1].set_yticks([- 2000, - 1000, 0])\n",
    "for i in range(2):\n",
    "    axmat[0, i].set_xlim(0, 500)\n",
    "    axmat[1, i].set_xlim(0, 500)\n",
    "    axmat[1, i].set_xticks([0, 200, 400])\n",
    "    axmat[1, i].set_xlabel('Episode', labelpad=10)\n",
    "axmat[0, 0].set_title('Mountain Car')\n",
    "axmat[0, 1].set_title('Acrobot')\n",
    "lgd = axmat[0, 0].legend(loc='upper right', bbox_to_anchor=(3.125, 0.85), frameon=False)\n",
    "fig.align_ylabels(axmat[:, 0])\n",
    "fig.subplots_adjust(hspace=0.0, wspace=0.375)\n",
    "fig.savefig('experiment_2_mountain_car_and_acrobot_interference.pdf', bbox_extra_artists=(lgd,), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=#top>Back to Top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sorted(list(set(optimizer_nice_names.values()) - {'Constant'}))\n",
    "y = [1, 4, 5, 6]\n",
    "fig, ax = plt.subplots(1, 1, dpi=300, figsize=(3.5, 2))\n",
    "ax.bar(x,\n",
    "       y,\n",
    "       0.6,\n",
    "       color=sns.color_palette('colorblind', 1)[0])\n",
    "ax.set_yticks([0, 2, 4, 6, 8])\n",
    "ax.set_ylim(0, 8)\n",
    "ax.set_ylabel('Number of Times in Top 2', labelpad=10)\n",
    "fig.tight_layout()\n",
    "fig.savefig('top_2.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
